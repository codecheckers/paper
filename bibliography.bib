
@ARTICLE{Gronenschild2012-pp,
  title    = "The effects of {FreeSurfer} version, workstation type, and
              Macintosh operating system version on anatomical volume and
              cortical thickness measurements",
  author   = "Gronenschild, Ed H B M and Habets, Petra and Jacobs, Heidi I L
              and Mengelers, Ron and Rozendaal, Nico and van Os, Jim and
              Marcelis, Machteld",
  abstract = "FreeSurfer is a popular software package to measure cortical
              thickness and volume of neuroanatomical structures. However,
              little if any is known about measurement reliability across
              various data processing conditions. Using a set of 30 anatomical
              T1-weighted 3T MRI scans, we investigated the effects of data
              processing variables such as FreeSurfer version (v4.3.1, v4.5.0,
              and v5.0.0), workstation (Macintosh and Hewlett-Packard), and
              Macintosh operating system version (OSX 10.5 and OSX 10.6).
              Significant differences were revealed between FreeSurfer version
              v5.0.0 and the two earlier versions. These differences were on
              average 8.8 $\pm$ 6.6\% (range 1.3-64.0\%) (volume) and 2.8 $\pm$
              1.3\% (1.1-7.7\%) (cortical thickness). About a factor two
              smaller differences were detected between Macintosh and
              Hewlett-Packard workstations and between OSX 10.5 and OSX 10.6.
              The observed differences are similar in magnitude as effect sizes
              reported in accuracy evaluations and neurodegenerative
              studies.The main conclusion is that in the context of an ongoing
              study, users are discouraged to update to a new major release of
              either FreeSurfer or operating system or to switch to a different
              type of workstation without repeating the analysis; results thus
              give a quantitative support to successive recommendations stated
              by FreeSurfer developers over the years. Moreover, in view of the
              large and significant cross-version differences, it is concluded
              that formal assessment of the accuracy of FreeSurfer is
              desirable.",
  journal  = "PLoS One",
  volume   =  7,
  number   =  6,
  pages    = "e38234",
  month    =  jun,
  year     =  2012,
  language = "en",
  issn     = "1932-6203",
  pmid     = "22675527",
  doi      = "10.1371/journal.pone.0038234",
  pmc      = "PMC3365894"
}

@article{cert-2020-001,
  author =	 {Stephen J. Eglen},
  title =	 {{CODECHECK} Certificate 2020-001},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Piccolo2020-lo,
  title    = "{ShinyLearner}: A containerized benchmarking tool for
              machine-learning classification of tabular data",
  author   = "Piccolo, Stephen R and Lee, Terry J and Suh, Erica and Hill,
              Kimball",
  journal  = "Gigascience",
  volume   =  9,
  number   =  4,
  month    =  apr,
  year     =  2020,
  keywords = "algorithm optimization; benchmark; classification; feature
              selection; machine learning; model selection; software
              containers; supervised learning",
  language = "en",
  issn     = "2047-217X",
  pmid     = "32249316",
  doi      = "10.1093/gigascience/giaa026",
  pmc      = "PMC7131989"
}

@article{cert-2020-002,
  author =	 {Stephen J. Eglen and Daniel N\"{u}st},
  title =	 {{CODECHECK} Certificate 2020-002},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Hancock1992-mp,
  title     = "The principal components of natural images",
  author    = "Hancock, Peter J B and Baddeley, Roland J and Smith, Leslie S",
  abstract  = "A neural net was used to analyse samples of natural images and
               text. For the natural images, components resemble derivatives of
               Gaussian operators, similar to those found in visual cortex and
               inferred from psychophysics. While the results from natural
               images do not depend on scale, those from text images are highly
               scale dependent. Convolution of one of the text components with
               an original image shows that it is sensitive to inter-word gaps.",
  journal   = "Network: Computation in Neural Systems",
  publisher = "Taylor \& Francis",
  volume    =  3,
  number    =  1,
  pages     = "61--70",
  year      =  1992,
  eprint    = "http://www.tandfonline.com/doi/pdf/10.1088/0954-898X\_3\_1\_008",
  doi       = "10.1088/0954-898X_3_1_008"
}

@article{cert-2020-003,
  author =	 {Daniel N\"{u}st},
  title =	 {{CODECHECK} Certificate 2020-003},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Hopfield1982-mz,
  title    = "Neural networks and physical systems with emergent collective
              computational abilities",
  author   = "Hopfield, J J",
  abstract = "Computational properties of use of biological organisms or to the
              construction of computers can emerge as collective properties of
              systems having a large number of simple equivalent components (or
              neurons). The physical meaning of content-addressable memory is
              described by an appropriate phase space flow of the state of a
              system. A model of such a system is given, based on aspects of
              neurobiology but readily adapted to integrated circuits. The
              collective properties of this model produce a content-addressable
              memory which correctly yields an entire memory from any subpart
              of sufficient size. The algorithm for the time evolution of the
              state of the system is based on asynchronous parallel processing.
              Additional emergent collective properties include some capacity
              for generalization, familiarity recognition, categorization,
              error correction, and time sequence retention. The collective
              properties are only weakly sensitive to details of the modeling
              or the failure of individual devices.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  79,
  number   =  8,
  pages    = "2554--2558",
  month    =  apr,
  year     =  1982,
  language = "en",
  issn     = "0027-8424",
  pmid     = "6953413",
  doi      = "10.1073/pnas.79.8.2554",
  pmc      = "PMC346238"
}

@article{cert-2020-004,
  author =	 {Daniel N\"{u}st},
  title =	 {{CODECHECK} Certificate 2020-004},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Barto1983-rg,
  title    = "Neuronlike adaptive elements that can solve difficult learning
              control problems",
  author   = "Barto, A G and Sutton, R S and Anderson, C W",
  abstract = "It is shown how a system consisting of two neuronlike adaptive
              elements can solve a difficult learning control problem. The task
              is to balance a pole that is hinged to a movable cart by applying
              forces to the cart's base. It is argued that the learning
              problems faced by adaptive elements that are components of
              adaptive networks are at least as difficult as this version of
              the pole-balancing problem. The learning system consists of a
              single associative search element (ASE) and a single adaptive
              critic element (ACE). In the course of learning to balance the
              pole, the ASE constructs associations between input and output by
              searching under the influence of reinforcement feedback, and the
              ACE constructs a more informative evaluation function than
              reinforcement feedback alone can provide. The differences between
              this approach and other attempts to solve problems using
              neurolike elements are discussed, as is the relation of this work
              to classical and instrumental conditioning in animal learning
              studies and its possible implications for research in the
              neurosciences.",
  journal  = "IEEE Trans. Syst. Man Cybern.",
  volume   = "SMC-13",
  number   =  5,
  pages    = "834--846",
  month    =  sep,
  year     =  1983,
  keywords = "adaptive control;learning systems;neural nets;neural
              nets;adaptive control;neuronlike adaptive elements;learning
              control problem;movable cart;associative search element;adaptive
              critic element;animal learning studies;Adaptive
              systems;Problem-solving;Training;Pattern
              recognition;Neurons;Supervised learning;Biological neural
              networks",
  issn     = "0018-9472, 2168-2909",
  doi      = "10.1109/TSMC.1983.6313077"
}

@article{cert-2020-005,
  author =	 {Stephen J. Eglen},
  title =	 {{CODECHECK} Certificate 2020-005},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{larisch_re_2019,
	title = {[{Re}] {Connectivity} reflects coding a model of voltage-based {STDP} with homeostasis},
	volume = {5},
	copyright = {Creative Commons Attribution 4.0 International, Open Access},
	doi = {10.5281/ZENODO.3538217},
	abstract = {Since the first description of spike-timing-dependent plasticity (STDP), different models of STDP has been published to reproduce different experimental findings. Clopath et al. (2010) introduced an STDP model which is able to reproduce the experimental findings of triplet studies. They implemented a homeostatic mechanism to control the level of generated LTD, based on the relationship between the average postsynaptic membrane potential and a reference value. With this voltage-based STDP rule, they reproduce a wide range of physiological experiments. We here present a reimplementation of the Clopath et al. (2010) learning rule in Python with the help of the neuro-simulator ANNarchy.},
	number = {3},
	journal = {ReScience C},
	author = {Larisch, Rene},
	month = nov,
	year = {2019},
	publisher = {Zenodo},
	keywords = {Computational Neuroscience, Python}
}

@article{cert-2020-006,
  author =	 {Stephen J. Eglen},
  title =	 {{CODECHECK} Certificate 2020-006},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{detorakis_re_2017,
	title = {[{Re}] {A} {Generalized} {Linear} {Integrate}-{And}-{Fire} {Neural} {Model} {Produces} {Diverse} {Spiking} {Behaviors}},
	volume = {3},
	copyright = {Creative Commons Attribution 4.0, Open Access},
	doi = {10.5281/ZENODO.1003214},
	abstract = {A Generalized Linear Integrate-and-Fire Neural Model Produces Diverse Spiking Behaviors, ReScience 3(7), 2017},
	number = {1},
	journal = {ReScience C},
	author = {Detorakis, Georgios},
	month = oct,
	year = {2017},
	publisher = {Zenodo},
	keywords = {generalized linear integrate-and-fire neuron, Python},
	pages = {\#7}
}

@article{cert-2020-007,
  author =	 {Stephen J. Eglen},
  title =	 {{CODECHECK} Certificate 2020-007},
  year =	 {2020},
  doi =		 {"TODO"},
  journal =	 {Zenodo}
}

@article{hathway_re_2018,
	title = {[{Re}] {Spike} {Timing} {Dependent} {Plasticity} {Finds} {The} {Start} {Of} {Repeating} {Patterns} {In} {Continuous} {Spike} {Trains}},
	volume = {4},
	copyright = {Creative Commons Attribution 4.0, Open Access},
	doi = {10.5281/ZENODO.1327348},
	abstract = {A reference implementation of Spike Timing Dependent Plasticity Finds the Start of Repeating Patterns in Continuous Spike Trains, Masquelier T, Guyonneau R, Thorpe SJ, PLoS ONE 3(1): e1377, 2008. https://doi.org/10.1371/journal.pone.0001377},
	language = {en},
	number = {1},
	journal = {ReScience C},
	author = {Hathway, Pamela and Goodman, Dan F. M.},
	month = aug,
	year = {2018},
	publisher = {Zenodo},
	keywords = {Brian, Python, Spatio-temporal spike pattern, STDP},
	pages = {\#6}
}

@article{cert-2020-008,
  author =	 {Stephen J. Eglen},
  title =	 {{CODECHECK} Certificate 2020-008},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@misc{davies-preprint-2020,
  title     = {Effects of non-pharmaceutical interventions on {COVID-19} cases,
               deaths, and demand for hospital services in the {UK}: a
               modelling study},
  author    = {Davies, Nicholas G and Kucharski, Adam J and Eggo, Rosalind M
               and Gimma, Amy and {CMMID COVID-19 working group} and Edmunds, W John},
  year      =  {2020},
  month = {April},
  url = {https://github.com/cmmid/cmmid.github.io/blob/master/topics/covid19/reports/uk_scenario_modelling_preprint_2020_04_01.pdf},
  urldate = {2021-01-11}
}

@ARTICLE{Davies2020-vj,
  title     = "Effects of non-pharmaceutical interventions on {COVID-19} cases,
               deaths, and demand for hospital services in the {UK}: a
               modelling study",
  author    = "Davies, Nicholas G and Kucharski, Adam J and Eggo, Rosalind M
               and Gimma, Amy and Edmunds, W John and Jombart, Thibaut and
               O'Reilly, Kathleen and Endo, Akira and Hellewell, Joel and
               Nightingale, Emily S and Quilty, Billy J and Jarvis, Christopher
               I and Russell, Timothy W and Klepac, Petra and Bosse, Nikos I
               and Funk, Sebastian and Abbott, Sam and Medley, Graham F and
               Gibbs, Hamish and Pearson, Carl A B and Flasche, Stefan and Jit,
               Mark and Clifford, Samuel and Prem, Kiesha and Diamond, Charlie
               and Emery, Jon and Deol, Arminder K and Procter, Simon R and van
               Zandvoort, Kevin and Sun, Yueqian Fiona and Munday, James D and
               Rosello, Alicia and Auzenbergs, Megan and Knight, Gwen and
               Houben, Rein M G J and Liu, Yang",
  abstract  = "BackgroundNon-pharmaceutical interventions have been implemented
               to reduce transmission of severe acute respiratory syndrome
               coronavirus 2 (SARS-CoV-2) in the UK. Projecting the size of an
               unmitigated epidemic and the potential effect of different
               control measures has been crucial to support evidence-based
               policy making during the early stages of the epidemic. This
               study assesses the potential impact of different control
               measures for mitigating the burden of COVID-19 in the UK.",
  journal   = "The Lancet Public Health",
  publisher = "Elsevier",
  month     =  jun,
  year      =  2020,
  issn      = "2468-2667",
  doi       = "10.1016/S2468-2667(20)30133-X"
}

@article{cert-2020-009,
  author =	 {Stephen J. Eglen},
  title =	 {{CODECHECK} Certificate 2020-009},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

% proper preprint https://doi.org/10.1101/2020.04.23.20077024, but checked before that
@misc{kucharski-preprint-2020,
  title     = {Effectiveness of isolation, testing, contact tracing and physical distancing on reducing transmission of SARS-CoV-2 in different settings: a mathematical modelling study},
  author    = {Kucharski, Adam J and Klepac, Petra and Conlan, Andrew J. K. and Kissler, Stephen M. and Tang, Maria and Fry, Hannah and Gog, Julia R. and Edmunds, W. John and {CMMID COVID-19 working group}},
  year      =  {2020},
  month = {April},
  url = {https://cmmid.github.io/topics/covid19/reports/bbc_contact_tracing.pdf},
  urldate = {2021-01-11}
}

% codecheck mentioned in acknowledgements but not linked to
@article{kucharski_effectiveness_2020,
	title = {Effectiveness of isolation, testing, contact tracing, and physical distancing on reducing transmission of {SARS}-{CoV}-2 in different settings: a mathematical modelling study},
	volume = {20},
	issn = {1473-3099, 1474-4457},
	shorttitle = {Effectiveness of isolation, testing, contact tracing, and physical distancing on reducing transmission of {SARS}-{CoV}-2 in different settings},
	doi = {10.1016/S1473-3099(20)30457-6},
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}h3{\textgreater}Background{\textless}/h3{\textgreater}{\textless}p{\textgreater}The isolation of symptomatic cases and tracing of contacts has been used as an early COVID-19 containment measure in many countries, with additional physical distancing measures also introduced as outbreaks have grown. To maintain control of infection while also reducing disruption to populations, there is a need to understand what combination of measures—including novel digital tracing approaches and less intensive physical distancing—might be required to reduce transmission. We aimed to estimate the reduction in transmission under different control measures across settings and how many contacts would be quarantined per day in different strategies for a given level of symptomatic case incidence.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Methods{\textless}/h3{\textgreater}{\textless}p{\textgreater}For this mathematical modelling study, we used a model of individual-level transmission stratified by setting (household, work, school, or other) based on BBC Pandemic data from 40 162 UK participants. We simulated the effect of a range of different testing, isolation, tracing, and physical distancing scenarios. Under optimistic but plausible assumptions, we estimated reduction in the effective reproduction number and the number of contacts that would be newly quarantined each day under different strategies.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Results{\textless}/h3{\textgreater}{\textless}p{\textgreater}We estimated that combined isolation and tracing strategies would reduce transmission more than mass testing or self-isolation alone: mean transmission reduction of 2\% for mass random testing of 5\% of the population each week, 29\% for self-isolation alone of symptomatic cases within the household, 35\% for self-isolation alone outside the household, 37\% for self-isolation plus household quarantine, 64\% for self-isolation and household quarantine with the addition of manual contact tracing of all contacts, 57\% with the addition of manual tracing of acquaintances only, and 47\% with the addition of app-based tracing only. If limits were placed on gatherings outside of home, school, or work, then manual contact tracing of acquaintances alone could have an effect on transmission reduction similar to that of detailed contact tracing. In a scenario where 1000 new symptomatic cases that met the definition to trigger contact tracing occurred per day, we estimated that, in most contact tracing strategies, 15 000–41 000 contacts would be newly quarantined each day.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Interpretation{\textless}/h3{\textgreater}{\textless}p{\textgreater}Consistent with previous modelling studies and country-specific COVID-19 responses to date, our analysis estimated that a high proportion of cases would need to self-isolate and a high proportion of their contacts to be successfully traced to ensure an effective reproduction number lower than 1 in the absence of other measures. If combined with moderate physical distancing measures, self-isolation and contact tracing would be more likely to achieve control of severe acute respiratory syndrome coronavirus 2 transmission.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Funding{\textless}/h3{\textgreater}{\textless}p{\textgreater}Wellcome Trust, UK Engineering and Physical Sciences Research Council, European Commission, Royal Society, Medical Research Council.{\textless}/p{\textgreater}},
	language = {English},
	number = {10},
	journal = {The Lancet Infectious Diseases},
	author = {Kucharski, Adam J. and Klepac, Petra and Conlan, Andrew J. K. and Kissler, Stephen M. and Tang, Maria L. and Fry, Hannah and Gog, Julia R. and Edmunds, W. John and Emery, Jon C. and Medley, Graham and Munday, James D. and Russell, Timothy W. and Leclerc, Quentin J. and Diamond, Charlie and Procter, Simon R. and Gimma, Amy and Sun, Fiona Yueqian and Gibbs, Hamish P. and Rosello, Alicia and Zandvoort, Kevin van and Hué, Stéphane and Meakin, Sophie R. and Deol, Arminder K. and Knight, Gwen and Jombart, Thibaut and Foss, Anna M. and Bosse, Nikos I. and Atkins, Katherine E. and Quilty, Billy J. and Lowe, Rachel and Prem, Kiesha and Flasche, Stefan and Pearson, Carl A. B. and Houben, Rein M. G. J. and Nightingale, Emily S. and Endo, Akira and Tully, Damien C. and Liu, Yang and Villabona-Arenas, Julian and O'Reilly, Kathleen and Funk, Sebastian and Eggo, Rosalind M. and Jit, Mark and Rees, Eleanor M. and Hellewell, Joel and Clifford, Samuel and Jarvis, Christopher I. and Abbott, Sam and Auzenbergs, Megan and Davies, Nicholas G. and Simons, David},
	month = oct,
	year = {2020},
	pmid = {32559451},
	publisher = {Elsevier},
	pages = {1151--1160}
}

@article{cert-2020-010,
  author =	 {Stephen J. Eglen},
  title =	 {{CODECHECK} Certificate 2020-001},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{ferguson_report_2020,
	title = {Report 9: {Impact} of non-pharmaceutical interventions ({NPIs}) to reduce {COVID19} mortality and healthcare demand},
	copyright = {© 2020. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License (https://creativecommons.org/licenses/by-nc-nd/4.0/).},
	abstract = {The global impact of COVID-19 has been profound, and the public health threat it represents is the most serious seen in a respiratory virus since the 1918 H1N1 influenza pandemic. Here we present the results of epidemiological modelling which has informed policymaking in the UK and other countries in recent weeks. In the absence of a COVID-19 vaccine, we assess the potential role of a number of public health measures – so-called non-pharmaceutical interventions (NPIs) – aimed at reducing contact rates in the population and thereby reducing transmission of the virus. In the results presented here, we apply a previously published microsimulation model to two countries: the UK (Great Britain specifically) and the US. We conclude that the effectiveness of any one intervention in isolation is likely to be limited, requiring multiple interventions to be combined to have a substantial impact on transmission. Two fundamental strategies are possible: (a) mitigation, which focuses on slowing but not necessarily stopping epidemic spread – reducing peak healthcare demand while protecting those most at risk of severe disease from infection, and (b) suppression, which aims to reverse epidemic growth, reducing case numbers to low levels and maintaining that situation indefinitely. Each policy has major challenges. We find that that optimal mitigation policies (combining home isolation of suspect cases, home quarantine of those living in the same household as suspect cases, and social distancing of the elderly and others at most risk of severe disease) might reduce peak healthcare demand by 2/3 and deaths by half. However, the resulting mitigated epidemic would still likely result in hundreds of thousands of deaths and health systems (most notably intensive care units) being overwhelmed many times over. For countries able to achieve it, this leaves suppression as the preferred policy option. We show that in the UK and US context, suppression will minimally require a combination of social distancing of the entire population, home isolation of cases and household quarantine of their family members. This may need to be supplemented by school and university closures, though it should be recognised that such closures may have negative impacts on health systems due to increased absenteeism. The major challenge of suppression is that this type of intensive intervention package – or something equivalently effective at reducing transmission – will need to be maintained until a vaccine becomes available (potentially 18 months or more) – given that we predict that transmission will quickly rebound if interventions are relaxed. We show that intermittent social distancing – triggered by trends in disease surveillance – may allow interventions to be relaxed temporarily in relative short time windows, but measures will need to be reintroduced if or when case numbers rebound. Last, while experience in China and now South Korea show that suppression is possible in the short term, it remains to be seen whether it is possible long-term, and whether the social and economic costs of the interventions adopted thus far can be reduced.},
	language = {en-US-GB},
	author = {Ferguson, N. and Laydon, D. and Nedjati Gilani, G. and Imai, N. and Ainslie, K. and Baguelin, M. and Bhatia, S. and Boonyasiri, A. and Cucunuba Perez, Z. and Cuomo-Dannenburg, G. and Dighe, A. and Dorigatti, I. and Fu, H. and Gaythorpe, K. and Green, W. and Hamlet, A. and Hinsley, W. and Okell, L. and Van Elsland, S. and Thompson, H. and Verity, R. and Volz, E. and Wang, H. and Wang, Y. and Walker, P. and Walters, C. and Winskill, P. and Whittaker, C. and Donnelly, C. and Riley, S. and Ghani, A.},
	month = mar,
	year = {2020},
	doi = {10.25561/77482}
}

@article{cert-2020-011,
  author =	 {Stephen J. Eglen},
  title =	 {{CODECHECK} Certificate 2020-001},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{flaxman_estimating_2020,
	title = {Estimating the effects of non-pharmaceutical interventions on {COVID}-19 in {Europe}},
	volume = {584},
	copyright = {2020 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	doi = {10.1038/s41586-020-2405-7},
	abstract = {Following the detection of the new coronavirus1 severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) and its spread outside of China, Europe has experienced large epidemics of coronavirus disease 2019 (COVID-19). In response, many European countries have implemented non-pharmaceutical interventions, such as the closure of schools and national lockdowns. Here we study the effect of major interventions across 11 European countries for the period from the start of the COVID-19 epidemics in February 2020 until 4 May 2020, when lockdowns started to be lifted. Our model calculates backwards from observed deaths to estimate transmission that occurred several weeks previously, allowing for the time lag between infection and death. We use partial pooling of information between countries, with both individual and shared effects on the time-varying reproduction number (Rt). Pooling allows for more information to be used, helps to overcome idiosyncrasies in the data and enables more-timely estimates. Our model relies on fixed estimates of some epidemiological parameters (such as the infection fatality rate), does not include importation or subnational variation and assumes that changes in Rt are an immediate response to interventions rather than gradual changes in behaviour. Amidst the ongoing pandemic, we rely on death data that are incomplete, show systematic biases in reporting and are subject to future consolidation. We estimate that—for all of the countries we consider here—current interventions have been sufficient to drive Rt below 1 (probability Rt {\textless} 1.0 is greater than 99\%) and achieve control of the epidemic. We estimate that across all 11 countries combined, between 12 and 15 million individuals were infected with SARS-CoV-2 up to 4 May 2020, representing between 3.2\% and 4.0\% of the population. Our results show that major non-pharmaceutical interventions—and lockdowns in particular—have had a large effect on reducing transmission. Continued intervention should be considered to keep transmission of SARS-CoV-2 under control.},
	language = {en},
	number = {7820},
	journal = {Nature},
	author = {Flaxman, Seth and Mishra, Swapnil and Gandy, Axel and Unwin, H. Juliette T. and Mellan, Thomas A. and Coupland, Helen and Whittaker, Charles and Zhu, Harrison and Berah, Tresnia and Eaton, Jeffrey W. and Monod, Mélodie and Ghani, Azra C. and Donnelly, Christl A. and Riley, Steven and Vollmer, Michaela A. C. and Ferguson, Neil M. and Okell, Lucy C. and Bhatt, Samir},
	month = aug,
	year = {2020},
	publisher = {Nature Publishing Group},
	pages = {257--261}
}

@article{cert-2020-012,
  author =	 {Stephen J. Eglen},
  title =	 {{CODECHECK} Certificate 2020-012},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}


@article{unwin_report_2020,
	title = {Report 23: {State}-level tracking of {COVID}-19 in the {United} {States}},
	shorttitle = {Report 23},
	abstract = {our estimates show that the percentage of individuals that have been infected is 4.1\% [3.7\%-4.5\%], with wide variation between states. For all states, even for the worst affected states, we estimate that less than a quarter of the population has been infected; in New York, for example, we estimate that 16.6\% [12.8\%-21.6\%] of individuals have been infected to date. Our attack rates for New York are in line with those from recent serological studies [1] broadly supporting our choice of infection fatality rate. There is variation in the initial reproduction number, which is likely due to a range of factors; we find a strong association between the initial reproduction number with both population density (measured at the state level) and the chronological date when 10 cumulative deaths occurred (a crude estimate of the date of locally sustained transmission). Our estimates suggest that the epidemic is not under control in much of the US: as of 17 May 2020 the reproduction number is above the critical threshold (1.0) in 24 [95\% CI: 20-30] states. Higher reproduction numbers are geographically clustered in the South and Midwest, where epidemics are still developing, while we estimate lower reproduction numbers in states that have already suffered high COVID-19 mortality (such as the Northeast). These estimates suggest that caution must be taken in loosening current restrictions if effective additional measures are not put in place. We predict that increased mobility following relaxation of social distancing will lead to resurgence of transmission, keeping all else constant. We predict that deaths over the next two-month period could exceed current cumulative deaths by greater than two-fold, if the relationship between mobility and transmission remains unchanged. Our results suggest that factors modulating transmission such as rapid testing, contact tracing and behavioural precautions are crucial to offset the rise of transmission associated with loosening of social distancing. Overall, we show that while all US states have substantially reduced their reproduction numbers, there is little evidence that any states are approaching herd immunity and thus the epidemic is close to over in any state.},
	language = {en-US-GB},
	author = {Unwin, H. and Mishra, S. and Bradley, V. C. and Gandy, A. and Vollmer, M. and Mellan, T. and Coupland, H. and Ainslie, K. and Whittaker, C. and Ish-Horowicz, J. and Filippi, S. and Xi, X. and Monod, M. and Ratmann, O. and Hutchinson, M. and Valka, F. and Zhu, H. and Hawryluk, I. and Milton, P. and Baguelin, M. and Boonyasiri, A. and Brazeau, N. and Cattarino, L. and Charles, G. and Cooper, L. and Cucunuba Perez, Z. and Cuomo-Dannenburg, G. and Djaafara, A. and Dorigatti, I. and Eales, O. and Eaton, J. and Van Elsland, S. and Fitzjohn, R. and Gaythorpe, K. and Green, W. and Hallett, T. and Hinsley, W. and Imai, N. and Jeffrey, B. and Knock, E. and Laydon, D. and Lees, J. and Nedjati Gilani, G. and Nouvellet, P. and Okell, L. and Ower, A. and Parag, K. and Siveroni, I. and Thompson, H. and Verity, R. and Walker, P. and Walters, C. and Wang, Y. and Watson, O. and Whittles, L. and Ghani, A. and Ferguson, N. and Riley, S. and Donnelly, C. and Bhatt, S. and Flaxman, S.},
	month = may,
	year = {2020},
	doi = {10.25561/79231}
}

@article{unwin_state-level_2020,
	title = {State-level tracking of {COVID}-19 in the {United} {States}},
	volume = {11},
	copyright = {2020 The Author(s)},
	issn = {2041-1723},
	doi = {10.1038/s41467-020-19652-6},
	abstract = {As of 1st June 2020, the US Centres for Disease Control and Prevention reported 104,232 confirmed or probable COVID-19-related deaths in the US. This was more than twice the number of deaths reported in the next most severely impacted country. We jointly model the US epidemic at the state-level, using publicly available death data within a Bayesian hierarchical semi-mechanistic framework. For each state, we estimate the number of individuals that have been infected, the number of individuals that are currently infectious and the time-varying reproduction number (the average number of secondary infections caused by an infected person). We use changes in mobility to capture the impact that non-pharmaceutical interventions and other behaviour changes have on the rate of transmission of SARS-CoV-2. We estimate that Rt was only below one in 23 states on 1st June. We also estimate that 3.7\% [3.4\%–4.0\%] of the total population of the US had been infected, with wide variation between states, and approximately 0.01\% of the population was infectious. We demonstrate good 3 week model forecasts of deaths with low error and good coverage of our credible intervals.},
	language = {en},
	number = {1},
	journal = {Nature Communications},
	author = {Unwin, H. Juliette T. and Mishra, Swapnil and Bradley, Valerie C. and Gandy, Axel and Mellan, Thomas A. and Coupland, Helen and Ish-Horowicz, Jonathan and Vollmer, Michaela A. C. and Whittaker, Charles and Filippi, Sarah L. and Xi, Xiaoyue and Monod, Mélodie and Ratmann, Oliver and Hutchinson, Michael and Valka, Fabian and Zhu, Harrison and Hawryluk, Iwona and Milton, Philip and Ainslie, Kylie E. C. and Baguelin, Marc and Boonyasiri, Adhiratha and Brazeau, Nick F. and Cattarino, Lorenzo and Cucunuba, Zulma and Cuomo-Dannenburg, Gina and Dorigatti, Ilaria and Eales, Oliver D. and Eaton, Jeffrey W. and van Elsland, Sabine L. and FitzJohn, Richard G. and Gaythorpe, Katy A. M. and Green, William and Hinsley, Wes and Jeffrey, Benjamin and Knock, Edward and Laydon, Daniel J. and Lees, John and Nedjati-Gilani, Gemma and Nouvellet, Pierre and Okell, Lucy and Parag, Kris V. and Siveroni, Igor and Thompson, Hayley A. and Walker, Patrick and Walters, Caroline E. and Watson, Oliver J. and Whittles, Lilith K. and Ghani, Azra C. and Ferguson, Neil M. and Riley, Steven and Donnelly, Christl A. and Bhatt, Samir and Flaxman, Seth},
	month = dec,
	year = {2020},
	publisher = {Nature Publishing Group},
	pages = {6189}
}

@article{cert-2020-013,
  author       = {Iain Davies},
  title        = {{CODECHECK} Certificate 2020-013},
  month        = jul,
  year         = 2020,
  publisher    = {Zenodo},
  journal    = {Zenodo},
  doi          = {10.5281/zenodo.3947959}
}

@article{Spitschan2020.06.02.129502,
	title = {Rest-activity cycles and melatonin phase angle of circadian entrainment in people without cone-mediated vision},
	doi = {10.1101/2020.06.02.129502},
	journal = {bioRxiv},
	author = {Spitschan, Manuel and Garbazza, Corrado and Kohl, Susanne and Cajochen, Christian},
	year = {2020},
	publisher = {Cold Spring Harbor Laboratory}
}

@article{cert-2020-014,
  author       = {Iain Davies},
  title        = {{CODECHECK} Certificate 2020-014},
  month        = jul,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3967326}
}

@article{Sadeh2020,
  doi = {10.7554/elife.52757},
  year = {2020},
  month = feb,
  publisher = {{eLife} Sciences Publications,  Ltd},
  volume = {9},
	issn = {2050-084X},
	editor = {Palmer, Stephanie and Frank, Michael J},
	pages = {e52757},
  author = {Sadra Sadeh and Claudia Clopath},
  title = {Patterned perturbation of inhibition can reveal the dynamical structure of neural processing},
  journal = {{eLife}}
}

@article{cert-2020-015,
  author       = {Iain Davies},
  title        = {{CODECHECK} Certificate 2020-015},
  month        = aug,
  year         = 2020,
  note         = {{See file LICENSE for license of the contained 
                   code. The report document codecheck.pdf is
                   published under CC-BY 4.0 International.}},
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3978402},
}

@article{Liou2020,
  doi = {10.7554/elife.50927},
  year = {2020},
  month = mar,
  publisher = {{eLife} Sciences Publications,  Ltd},
  volume = {9},
	pages = {e50927},
  author = {Jyun-you Liou and Elliot H Smith and Lisa M Bateman and Samuel L Bruce and Guy M McKhann and Robert R Goodman and Ronald G Emerson and Catherine A Schevon and LF Abbott},
  title = {A model for focal seizure onset,  propagation,  evolution,  and progression},
	issn = {2050-084X},
	editor = {Calabrese, Ronald L and Ramirez, Jan-Marino and Ramirez, Jan-Marino and Staley, Kevin and Khambhati, AN},
  journal = {{eLife}}
}

@article{cert-2020-016,
  author       = {Daniel N\"ust},
  title        = {{CODECHECK} Certificate 2020-016},
  month        = jun,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3981253}
}

@article{Brunsdon2020,
  doi = {10.1007/s10109-020-00334-2},
  year = {2020},
  month = aug,
  publisher = {Springer Science and Business Media {LLC}},
  author = {Chris Brunsdon and Alexis Comber},
  title = {Opening practice: supporting reproducibility and critical spatial data science},
  journal = {Journal of Geographical Systems}
}

@article{cert-2020-017,
  author       = {Daniel N\"ust},
  title        = {{CODECHECK} Certificate 2020-017},
  month        = aug,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.4003848}
}

@article{Bivand2020,
  doi = {10.1007/s10109-020-00336-0},
  year = {2020},
  publisher = {Springer Science and Business Media {LLC}},
  author = {Bivand, Roger S.},
  title = {Progress in the R ecosystem for representing and handling spatialdata},
  journal = {Journal of Geographical Systems}
}

@article{cert-2020-018,
  doi = {10.17605/OSF.IO/ZTC7M},
  author = {N\"{u}st,  Daniel},
  title = {Reproducibility review of: Integrating cellular automata and discrete global grid systems: a case study into wildfire modelling},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Hojati2020,
  doi = {10.5194/agile-giss-1-6-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--23},
  author = {Majid Hojati and Colin Robertson},
  title = {Integrating cellular automata and discrete global grid systems: a case study into wildfire modelling},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-019,
  doi = {10.17605/OSF.IO/5SVMT},
  author = {N\"{u}st,  Daniel and Granell,  Carlos},
  title = {Reproducibility review of: What to do in the Meantime: A Service Coverage Analysis for Parked Autonomous Vehicles},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Illium2020,
  doi = {10.5194/agile-giss-1-7-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--15},
  author = {Steffen Illium and Philipp Andreas Friese and Robert M\"{u}ller and Sebastian Feld},
  title = {What to do in the Meantime: A Service Coverage Analysis for Parked Autonomous Vehicles},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-020,
  doi = {10.17605/OSF.IO/7TWR2},
  author = {N\"{u}st,  Daniel and Ostermann,  Frank},
  title = {Reproducibility review of: Window Operators for Processing Spatio-Temporal Data Streams on Unmanned Vehicles},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Werner2020,
  doi = {10.5194/agile-giss-1-21-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--23},
  author = {Tobias Werner and Thomas Brinkhoff},
  title = {Window Operators for Processing Spatio-Temporal Data Streams on Unmanned Vehicles},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-021,
  doi = {10.17605/OSF.IO/SUWPJ},
  author = {Ostermann,  Frank and N\"{u}st,  Daniel},
  title = {Reproducibility Review of: Comparing supervised learning algorithms for Spatial Nominal Entity recognition},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Medad2020,
  doi = {10.5194/agile-giss-1-15-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--18},
  author = {Amine Medad and Mauro Gaio and Ludovic Moncla and S{\'{e}}bastien Musti{\`{e}}re and Yannick Le Nir},
  title = {Comparing supervised learning algorithms for Spatial Nominal Entity recognition},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-022,
  doi = {10.17605/OSF.IO/7XRQG},
  author = {N\"{u}st,  Daniel},
  title = {Reproducibility review of: Extracting interrogative intents and concepts from geo-analytic questions},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Xu2020,
  doi = {10.5194/agile-giss-1-23-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--21},
  author = {Haiqi Xu and Ehsan Hamzei and Enkhbold Nyamsuren and Han Kruiger and Stephan Winter and Martin Tomko and Simon Scheider},
  title = {Extracting interrogative intents and concepts from geo-analytic questions},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-023,
  doi = {10.17605/OSF.IO/XS5YR},
  author = {Ostermann,  Frank and N\"{u}st,  Daniel},
  title = {Reproducibility review of: Tracking Hurricane Dorian in GDELT and Twitter},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Owuor2020,
  doi = {10.5194/agile-giss-1-19-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--18},
  author = {Innocensia Owuor and Hartwig H. Hochmair and Sreten Cvetojevic},
  title = {Tracking Hurricane Dorian in {GDELT} and Twitter},
  journal = {{AGILE}: {GIScience} Series}
}

@ARTICLE{Barnes2010-iv,
  title   = "Publish your computer code: it is good enough",
  author  = "Barnes, Nick",
  journal = "Nature",
  volume  =  467,
  number  =  7317,
  pages   = "753",
  month   =  oct,
  year    =  2010,
  issn    = "0028-0836, 1476-4687",
  pmid    = "20944687",
  doi     = "10.1038/467753a"
}

@article{sandve_ten_2013,
	title = {Ten {Simple} {Rules} for {Reproducible} {Computational} {Research}},
	volume = {9},
	doi = {10.1371/journal.pcbi.1003285},
	number = {10},
	journal = {PLoS Comput Biol},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	year = {2013},
	keywords = {Archives, Computer and information sciences, Computer applications, Habits, Replication studies, Reproducibility, Sequence analysis, Source code},
	pages = {e1003285}
}

@article{rule_ten_2019,
	title = {Ten simple rules for writing and sharing computational analyses in {Jupyter} {Notebooks}},
	volume = {15},
	issn = {1553-7358},
	doi = {10.1371/journal.pcbi.1007007},
	language = {en},
	number = {7},
	journal = {PLOS Computational Biology},
	author = {Rule, Adam and Birmingham, Amanda and Zuniga, Cristal and Altintas, Ilkay and Huang, Shih-Cheng and Knight, Rob and Moshiri, Niema and Nguyen, Mai H. and Rosenthal, Sara Brin and Pérez, Fernando and Rose, Peter W.},
	year = {2019},
	keywords = {Reproducibility, Data processing, Computer and information sciences, Metadata, Analysts, Computer hardware, Ecosystems, Graphical user interfaces},
	pages = {e1007007}
}

@article{peng_reproducible_2011,
	title = {Reproducible {Research} in {Computational} {Science}},
	volume = {334},
	copyright = {Copyright © 2011, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.1213847},
	abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
	language = {en},
	number = {6060},
	journal = {Science},
	author = {Peng, Roger D.},
	year = {2011},
	pmid = {22144613},
	pages = {1226--1227}
}

@article{barba_terminologies_2018,
	title = {Terminologies for {Reproducible} {Research}},
	url = {http://arxiv.org/abs/1802.03311},
	abstract = {Reproducible research---by its many names---has come to be regarded as a key concern across disciplines and stakeholder groups. Funding agencies and journals, professional societies and even mass media are paying attention, often focusing on the so-called "crisis" of reproducibility. One big problem keeps coming up among those seeking to tackle the issue: different groups are using terminologies in utter contradiction with each other. Looking at a broad sample of publications in different fields, we can classify their terminology via decision tree: they either, A---make no distinction between the words reproduce and replicate, or B---use them distinctly. If B, then they are commonly divided in two camps. In a spectrum of concerns that starts at a minimum standard of "same data+same methods=same results," to "new data and/or new methods in an independent study=same findings," group 1 calls the minimum standard reproduce, while group 2 calls it replicate. This direct swap of the two terms aggravates an already weighty issue. By attempting to inventory the terminologies across disciplines, I hope that some patterns will emerge to help us resolve the contradictions.},
	journal = {arXiv:1802.03311 [cs]},
	author = {Barba, Lorena A.},
	year = {2018},
	keywords = {Computer Science - Digital Libraries}
}

@article{chen_open_2019,
	title = {Open is not enough},
	volume = {15},
	copyright = {2018 Springer Nature Limited},
	issn = {1745-2481},
	doi = {10.1038/s41567-018-0342-2},
	abstract = {The solutions adopted by the high-energy physics community to foster reproducible research are examples of best practices that could be embraced more widely. This first experience suggests that reproducibility requires going beyond openness.},
	language = {En},
	number = {2},
	journal = {Nature Physics},
	author = {Chen, Xiaoli and Dallmeier-Tiessen, S{\"u}nje and Dasler, Robin and Feger, Sebastian and Fokianos, Pamfilos and Gonzalez, Jose Benito and Hirvonsalo, Harri and Kousidis, Dinos and Lavasa, Artemis and Mele, Salvatore and Rodríguez, Diego and \v{S}imko, Tibor and Smith, Tim and Trisovic, Ana and Trzcinska, Anna and Tsanaktsidis, Ioannis and Zimmermann, Markus and Cranmer, Kyle and Heinrich, Lukas and Watts, Gordon and Hildreth, Michael and Iglesias, Lara Lloret and Lassila-Perini, Kati and Neubert, Sebastian},
	year = {2019},
	pages = {113}
}

@article{schonbrodt_training_2019,
	title = {Training students for the {Open} {Science} future},
	volume = {3},
	issn = {2397-3374},
	doi = {10.1038/s41562-019-0726-z},
	language = {en},
	number = {10},
	journal = {Nature Human Behaviour},
	author = {Sch{\"o}nbrodt, Felix},
	year = {2019},
	pages = {1031--1031}
}

@article{piwowar_altmetrics:_2013,
	title = {Altmetrics: {Value} all research products},
	volume = {493},
	copyright = {2013 Nature Publishing Group},
	issn = {1476-4687},
	shorttitle = {Altmetrics},
	doi = {10.1038/493159a},
	abstract = {A new funding policy by the US National Science Foundation represents a sea-change in how researchers are evaluated, says Heather Piwowar.},
	language = {en},
	journal = {Nature},
	author = {Piwowar, Heather},
	year = {2013},
	pages = {159}
}

@article{donoho_invitation_2010,
	title = {An invitation to reproducible computational research},
	volume = {11},
	issn = {1465-4644},
	doi = {10.1093/biostatistics/kxq028},
	abstract = {I am genuinely thrilled to see Biostatistics make a formal venture into computational reproducibility, and I congratulate the editors of Biostatistics on taking},
	language = {en},
	number = {3},
	journal = {Biostatistics},
	author = {Donoho, David L.},
	year = {2010},
	pages = {385--388}
}

@incollection{claerbout_electronic_1992,
	series = {{SEG} {Technical} {Program} {Expanded} {Abstracts}},
	title = {Electronic documents give reproducible research a new meaning},
	doi = {10.1190/1.1822162},
	booktitle = {{SEG} {Technical} {Program} {Expanded} {Abstracts} 1992},
	publisher = {Society of Exploration Geophysicists},
	author = {Claerbout, J. and Karrenbach, M.},
	year = {1992},
	pages = {601--604}
}

@article{markowetz_five_2015,
	title = {Five selfish reasons to work reproducibly},
	volume = {16},
	issn = {1474-760X},
	doi = {10.1186/s13059-015-0850-7},
	abstract = {And so, my fellow scientists: ask not what you can do for reproducibility; ask what reproducibility can do for you! Here, I present five reasons why working reproducibly pays off in the long run and is in the self-interest of every ambitious, career-oriented scientist.},
	journal = {Genome Biology},
	author = {Markowetz, Florian},
	year = {2015},
	keywords = {Reproducibility, Scientific career},
	pages = {274}
}

@article{gentleman_statistical_2007,
	title = {Statistical {Analyses} and {Reproducible} {Research}},
	volume = {16},
	issn = {1061-8600},
	doi = {10.1198/106186007X178663},
	abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents---including figures, tables, and so on---can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection.The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
	number = {1},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Gentleman, Robert and Lang, Duncan Temple},
	year = {2007},
	pages = {1--23}
}

@article{boettiger_introduction_2015,
	title = {An {Introduction} to {Docker} for {Reproducible} {Research}},
	volume = {49},
	issn = {0163-5980},
	doi = {10.1145/2723872.2723882},
	abstract = {As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.},
	number = {1},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Boettiger, Carl},
	year = {2015},
	keywords = {Computer Science - Software Engineering},
	pages = {71--79}
}

@article{howe_virtual_2012,
	title = {Virtual {Appliances}, {Cloud} {Computing}, and {Reproducible} {Research}},
	volume = {14},
	issn = {1521-9615},
	doi = {10.1109/MCSE.2012.62},
	abstract = {As science becomes increasingly computational, reproducibility has become increasingly difficult, perhaps surprisingly. In many contexts, virtualization and cloud computing can mitigate the issues involved without significant overhead to the researcher, enabling the next generation of rigorous and reproducible computational science.},
	number = {4},
	journal = {Computing in Science Engineering},
	author = {Howe, B.},

	year = {2012},
	keywords = {case studies in scientific applications, Cloud computing, context awareness, Documentation, Information Retrieval, Information Storage and Retrieval, Reproducibility of results, reproducible results, research and development, Scientific computing, services computing, Virtual machining},
	pages = {36--41}
}

@article{kurtzer_singularity:_2017,
	title = {Singularity: {Scientific} containers for mobility of compute},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {Singularity},
	doi = {10.1371/journal.pone.0177459},
	abstract = {Here we present Singularity, software developed to bring containers and reproducibility to scientific computing. Using Singularity containers, developers can work in reproducible environments of their choosing and design, and these complete environments can easily be copied and executed on other platforms. Singularity is an open source initiative that harnesses the expertise of system and software engineers and researchers alike, and integrates seamlessly into common workflows for both of these groups. As its primary use case, Singularity brings mobility of computing to both users and HPC centers, providing a secure means to capture and distribute software and compute environments. This ability to create and deploy reproducible environments across these centers, a previously unmet need, makes Singularity a game changing development for computational science.},
	number = {5},
	journal = {PLOS ONE},
	author = {Kurtzer, Gregory M. and Sochat, Vanessa and Bauer, Michael W.},
	year = {2017},
	keywords = {Computer software, Operating Systems, software development, Open source software, Software tools, Research validity, Tar, Software design},
	pages = {e0177459}
}

@article{knuth_literate_1984,
	title = {Literate {Programming}},
	volume = {27},
	issn = {0010-4620},
	doi = {10.1093/comjnl/27.2.97},
	number = {2},
	journal = {Comput. J.},
	author = {Knuth, Donald E.},
	year = {1984},
	pages = {97--111}
}

@misc{marwick_how_2015,
	title = {How computers broke science – and what we can do to fix it},
	copyright = {Copyright © 2010–2019, The Conversation Trust (UK) Limited},
	url = {http://theconversation.com/how-computers-broke-science-and-what-we-can-do-to-fix-it-49938},
	abstract = {Virtually every researcher relies on computers to collect or analyze data. But when computers are opaque black boxes that manipulate data, it's impossible to replicate studies – a core value for science.},
	language = {en},
	urldate = {2017-07-05},
	journal = {The Conversation},
	author = {Marwick, Ben},
	year = {2015}
}

@article{eglen_recent_2018,
	title = {Recent developments in scholarly publishing to improve research practices in the life sciences},
	volume = {2},
	copyright = {© 2018 The Author(s). https://creativecommons.org/licenses/by-nc-nd/4.0/This is an open access article published by Portland Press Limited on behalf of the Biochemical Society and the Royal Society of Biology and distributed under the Creative Commons Attribution License 4.0 (CC BY-NC-ND).},
	issn = {2397-8554, 2397-8562},
	doi = {10.1042/ETLS20180172},
	abstract = {We outline recent developments in scholarly publishing that we think will improve the working environment and career prospects for life scientists. Most prominently, we discuss two key developments. (1) Life scientists are now embracing a preprint culture leading to rapid dissemination of research findings. (2) We outline steps to overcome the reproducibility crisis. We also briefly describe other innovations in scholarly publishing, along with changes to open access mandates from funding agencies.},
	language = {en},
	number = {6},
	journal = {Emerging Topics in Life Sciences},
	author = {Eglen, Stephen J. and Mounce, Ross and Gatto, Laurent and Currie, Adrian M. and Nobis, Yvonne},
	year = {2018},
	pages = {775--778}
}

@article{fanelli_opinion:_2018,
	title = {Opinion: {Is} science really facing a reproducibility crisis, and do we need it to?},
	copyright = {© 2018 . Published under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Opinion},
	doi = {10.1073/pnas.1708272114},
	abstract = {Efforts to improve the reproducibility and integrity of science are typically justified by a narrative of crisis, according to which most published results are unreliable due to growing problems with research and publication practices. This article provides an overview of recent evidence suggesting that this narrative is mistaken, and argues that a narrative of epochal changes and empowerment of scientists would be more accurate, inspiring, and compelling.},
	language = {en},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Fanelli, Daniele},
	year = {2018},
	pmid = {29531051},
	keywords = {reproducible research, bias, crisis, integrity, misconduct},
	pages = {201708272}
}

@article{eglen_toward_2017,
	title = {Toward standard practices for sharing computer code and programs in neuroscience},
	volume = {20},
	copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	doi = {10.1038/nn.4550},
	abstract = {Computational techniques are central in many areas of neuroscience and are relatively easy to share. This paper describes why computer programs underlying scientific publications should be shared and lists simple steps for sharing. Together with ongoing efforts in data sharing, this should aid reproducibility of research.},
	language = {en},
	number = {6},
	journal = {Nature Neuroscience},
	author = {Eglen, Stephen J. and Marwick, Ben and Halchenko, Yaroslav O. and Hanke, Michael and Sufi, Shoaib and Gleeson, Padraig and Silver, R. Angus and Davison, Andrew P. and Lanyon, Linda and Abrams, Mathew and Wachtler, Thomas and Willshaw, David J. and Pouzat, Christophe and Poline, Jean-Baptiste},
	year = {2017},
	pages = {770--773}
}

@article{kluyver_jupyter_2016,
	title = {Jupyter {Notebooks} - a publishing format for reproducible computational workflows},
	doi = {10.3233/978-1-61499-649-1-87},
	abstract = {It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.},
	journal = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
	author = {Kluyver, Thomas and Ragan-Kelley, Benjamin and Pérez, Fernando and Granger, Brian and Bussonier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica and Grout, Jason and Corlay, Sylvan and Ivanov, Paul and Avila, Damián and Abdallan, Safia and Willing, Carol and Jupyter Development Team},
	year = {2016},
	pages = {87--90}
}

@article{perignon_certify_2019,
	title = {Certify reproducibility with confidential data},
	volume = {365},
	copyright = {Copyright © 2019, American Association for the Advancement of Science. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aaw2825},
	abstract = {A trusted third party certifies that results reproduce
A trusted third party certifies that results reproduce},
	language = {en},
	number = {6449},
	journal = {Science},
	author = {Pérignon, Christophe and Gadouche, Kamel and Hurlin, Christophe and Silberman, Roxane and Debonnel, Eric},
	year = {2019},
	pmid = {31296759},
	pages = {127--128}
}

@article{tennant_ten_2019,
	title = {Ten {Hot} {Topics} around {Scholarly} {Publishing}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	doi = {10.3390/publications7020034},
	abstract = {The changing world of scholarly communication and the emerging new wave of \&lsquo;Open Science\&rsquo; or \&lsquo;Open Research\&rsquo; has brought to light a number of controversial and hotly debated topics. Evidence-based rational debate is regularly drowned out by misinformed or exaggerated rhetoric, which does not benefit the evolving system of scholarly communication. This article aims to provide a baseline evidence framework for ten of the most contested topics, in order to help frame and move forward discussions, practices, and policies. We address issues around preprints and scooping, the practice of copyright transfer, the function of peer review, predatory publishers, and the legitimacy of \&lsquo;global\&rsquo; databases. These arguments and data will be a powerful tool against misinformation across wider academic research, policy and practice, and will inform changes within the rapidly evolving scholarly publishing system.},
	language = {en},
	number = {2},
	journal = {Publications},
	author = {Tennant, Jonathan P. and Crane, Harry and Crick, Tom and Davila, Jacinto and Enkhbayar, Asura and Havemann, Johanna and Kramer, Bianca and Martin, Ryan and Masuzzo, Paola and Nobes, Andy and Rice, Curt and Rivera-López, Bárbara and Ross-Hellauer, Tony and Sattler, Susanne and Thacker, Paul D. and Vanholsbeeck, Marc},
	year = {2019},
	keywords = {copyright, impact factor, open access, open science, peer review, research evaluation, scholarly communication, Scopus, web of science},
	pages = {34}
}

@article{marwick_packaging_2018,
	title = {Packaging {Data} {Analytical} {Work} {Reproducibly} {Using} {R} (and {Friends})},
	volume = {72},
	issn = {0003-1305},
	doi = {10.1080/00031305.2017.1375986},
	abstract = {Computers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognizable way for organizing the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
	number = {1},
	journal = {The American Statistician},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	year = {2018},
	keywords = {Computational science, Data science, Open source software, Reproducible research},
	pages = {80--88}
}

@article{pebesma_r_2012,
	title = {The {R} software environment in reproducible geoscientific research},
	volume = {93},
	issn = {2324-9250},
	doi = {10.1029/2012EO160003},
	abstract = {Reproducibility is an important aspect of scientific research, because the credibility of science is at stake when research is not reproducible. Like science, the development of good, reliable scientific software is a social process. A mature and growing community relies on the R software environment for carrying out geoscientific research. Here we describe why people use R and how it helps in communicating and reproducing research.},
	language = {en},
	number = {16},
	journal = {Eos, Transactions American Geophysical Union},
	author = {Pebesma, Edzer and N\"ust, Daniel and Bivand, Roger},
	year = {2012},
	keywords = {R project, reproducible research, 0520 Data analysis: algorithms and implementation, 1978 Software re-use, 0530 Data presentation and visualization, 1694 Instruments and techniques, 1819 Hydrology: Geographic Information Systems (GIS)},
	pages = {163--163}
}

@article{stodden_empirical_2018,
	title = {An empirical analysis of journal policy effectiveness for computational reproducibility},
	volume = {115},
	copyright = {© 2018 . Published under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1708290115},
	abstract = {A key component of scientific communication is sufficient information for other researchers in the field to reproduce published findings. For computational and data-enabled research, this has often been interpreted to mean making available the raw data from which results were generated, the computer code that generated the findings, and any additional information needed such as workflows and input parameters. Many journals are revising author guidelines to include data and code availability. This work evaluates the effectiveness of journal policy that requires the data and code necessary for reproducibility be made available postpublication by the authors upon request. We assess the effectiveness of such a policy by (i) requesting data and code from authors and (ii) attempting replication of the published findings. We chose a random sample of 204 scientific papers published in the journal Science after the implementation of their policy in February 2011. We found that we were able to obtain artifacts from 44\% of our sample and were able to reproduce the findings for 26\%. We find this policy—author remission of data and code postpublication upon request—an improvement over no policy, but currently insufficient for reproducibility.},
	language = {en},
	number = {11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun},
	year = {2018},
	pmid = {29531050},
	keywords = {reproducible research, data access, open science, code access, reproducibility policy},
	pages = {2584--2589}
}

@article{stodden_legal_2009,
	title = {The {Legal} {Framework} for {Reproducible} {Scientific} {Research}: {Licensing} and {Copyright}},
	volume = {11},
	issn = {1521-9615},
	shorttitle = {The {Legal} {Framework} for {Reproducible} {Scientific} {Research}},
	doi = {10.1109/MCSE.2009.19},
	number = {1},
	journal = {Computing in Science \& Engineering},
	author = {Stodden, Victoria},
	year = {2009},
	pages = {35--40}
}

@article{greenbaum_structuring_2017,
	title = {Structuring supplemental materials in support of reproducibility},
	volume = {18},
	issn = {1474-760X},
	doi = {10.1186/s13059-017-1205-3},
	abstract = {Supplements are increasingly important to the scientific record, particularly in genomics. However, they are often underutilized. Optimally, supplements should make results findable, accessible, interoperable, and reusable (i.e., “FAIR”). Moreover, properly off-loading to them the data and detail in a paper could make the main text more readable. We propose a hierarchical organization for supplements, with some parts paralleling and “shadowing” the main text and other elements branching off from it, and we suggest a specific formatting to make this structure explicit. Furthermore, sections of the supplement could be presented in multiple scientific “dialects”, including machine-readable and lay-friendly formats.},
	number = {1},
	journal = {Genome Biology},
	author = {Greenbaum, Dov and Rozowsky, Joel and Stodden, Victoria and Gerstein, Mark},
	year = {2017},
	pages = {64}
}

@inproceedings{katz_software_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Software {Citation} in {Theory} and {Practice}},
	isbn = {978-3-319-96418-8},
	doi = {10.1007/978-3-319-96418-8_34},
	abstract = {In most fields, computational models and data analysis have become a significant part of how research is performed, in addition to the more traditional theory and experiment. Mathematics is no exception to this trend. While the system of publication and credit for theory and experiment (journals and books, often monographs) has developed and has become an expected part of the culture, how research is shared and how candidates for hiring, promotion are evaluated, software (and data) do not have the same history. A group working as part of the FORCE11 community developed a set of principles for software citation that fit software into the journal citation system, allow software to be published and then cited, and there are now over 50,000 DOIs that have been issued for software. However, some challenges remain, including: promoting the idea of software citation to developers and users; collaborating with publishers to ensure that systems collect and retain required metadata; ensuring that the rest of the scholarly infrastructure, particularly indexing sites, include software; working with communities so that software efforts “count”; and understanding how best to cite software that has not been published.},
	language = {en},
	booktitle = {Mathematical {Software} – {ICMS} 2018},
	publisher = {Springer International Publishing},
	author = {Katz, Daniel S. and Chue Hong, Neil P.},
	editor = {Davenport, James H. and Kauers, Manuel and Labahn, George and Urban, Josef},
	year = {2018},
	keywords = {Bibliometrics, Credit, Software citation, Software identifiers, Software metadata, Software repositories},
	pages = {289--296}
}

@article{neumann_datacite_2014,
	title = {{DataCite} and {DOI} names for research data},
	volume = {28},
	issn = {1573-4951},
	doi = {10.1007/s10822-014-9776-5},
	abstract = {The publication of research data is still not a widespread practice in many disciplines. The lack of acceptance of data as scientific output equal to scientific articles, and the lack of suitable infrastructures for the storage of data make it difficult to publish and cite data independently. The global consortium DataCite was established in 2009 to overcome the challenges of data citation. The aim of the consortium is to establish easy access to data, to increase the acceptance of data publication and to support data archiving. The use of Digital Object Identifiers (DOI) provides an easy method to access and re-use research data. The DOI facilitates the citation of data and therefore increases the availability and acknowledgement of research data.},
	language = {en},
	number = {10},
	journal = {Journal of Computer-Aided Molecular Design},
	author = {Neumann, Janna and Brase, Jan},
	year = {2014},
	keywords = {Data citation, Digital Object Identifier, Global consortium, Research data},
	pages = {1035--1041}
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	copyright = {2016 Nature Publishing Group},
	issn = {2052-4463},
	doi = {10.1038/sdata.2016.18},
	abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	language = {en},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	year = {2016},
	pages = {160018}
}

@book{xie_dynamic_2015,
	title = {Dynamic {Documents} with {R} and knitr, {Second} {Edition}},
	isbn = {978-1-4987-1697-0},
	abstract = {Quickly and Easily Write Dynamic Documents Suitable for both beginners and advanced users, Dynamic Documents with R and knitr, Second Edition makes writing statistical reports easier by integrating computing directly with reporting. Reports range from homework, projects, exams, books, blogs, and web pages to virtually any documents related to statistical graphics, computing, and data analysis. The book covers basic applications for beginners while guiding power users in understanding the extensibility of the knitr package. New to the Second Edition  A new chapter that introduces R Markdown v2 Changes that reflect improvements in the knitr package New sections on generating tables, defining custom printing methods for objects in code chunks, the C/Fortran engines, the Stan engine, running engines in a persistent session, and starting a local server to serve dynamic documents Boost Your Productivity in Statistical Report Writing and Make Your Scientific Computing with R Reproducible Like its highly praised predecessor, this edition shows you how to improve your efficiency in writing reports. The book takes you from program output to publication-quality reports, helping you fine-tune every aspect of your report.},
	language = {en},
	publisher = {CRC Press},
	author = {Xie, Yihui},
	year = {2015},
	keywords = {Business \& Economics / Statistics, Computers / Mathematical \& Statistical Software, Mathematics / Probability \& Statistics / General}
}

@article{lees_open_2012,
	title = {Open and {Free}: {Software} and {Scientific} {Reproducibility}},
	volume = {83},
	copyright = {© 2012 by the Seismological Society of America},
	issn = {0895-0695, 1938-2057},
	shorttitle = {Open and {Free}},
	doi = {10.1785/0220120091},
	abstract = {Recent scandals, retractions and proliferation of scientific research has reached a stage where scrutiny of scientific debate is now routinely reported in the public press as evidence of bungling, or, worse, dishonesty, in our profession (see Zimmer, 2012; Reay, 2010). High profile cases, like the discredited cancer research at Duke University or the notorious “Climate‐gate”, can be traced back to poor implementation of checks and balances on standard scientific practice. One remedy is to require researchers to use open methods of analysis, to share software, and to submit only reproducible analysis where it is feasible. Barriers to reproducibility are propriety (closed) software and computer platforms that encourage, rather than prevent, sloppy documentation. It is time to remind ourselves of efforts, perhaps started in the 1980’s, to reestablish standards of reproducibility (see Schwab et al. , 1996).

It has been a couple years now that I have acted as editor‐in‐chief of SRL, Seismological Research Letters . In the capacity of editor I handle papers submitted by authors all over the world. Some time ago a paper came across my desk formatted with an older version of a very popular word processor. I will not mention any names, but this software is used, nearly universally, by scientists and professionals around the world. The paper included equations formatted with an outdated system, a set of routines supplied by the corporate software publisher of the word processor that have since been superseded by newer, costly upgrades.

Since the submission was formatted in this manner, I could not …},
	language = {en},
	number = {5},
	journal = {Seismological Research Letters},
	author = {Lees, Jonathan M.},
	year = {2012},
	pages = {751--752}
}

@article{buck_solving_2015,
	title = {Solving reproducibility},
	volume = {348},
	copyright = {Copyright © 2015, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aac8041},
	language = {en},
	number = {6242},
	
	journal = {Science},
	author = {Buck, Stuart},
	year = {2015},
	pmid = {26113692},
	pages = {1403--1403}
}

@article{jupyter_binder_2018,
	title = {Binder 2.0 - {Reproducible}, interactive, sharable environments for science at scale},
	doi = {10.25080/Majora-4af1f417-011},
	journal = {Proceedings of the 17th Python in Science Conference},
	author = {Jupyter, Project and Bussonnier, Matthias and Forde, Jessica and Freeman, Jeremy and Granger, Brian and Head, Tim and Holdgraf, Chris and Kelley, Kyle and Nalvarte, Gladys and Osheroff, Andrew and Pacer, M. and Panda, Yuvi and Perez, Fernando and Ragan-Kelley, Benjamin and Willing, Carol},
	year = {2018},
	pages = {113--120}
}

@manual{nust_agile_2019,
	title = {{AGILE} {Reproducible} {Paper} {Guidelines}},
	doi = {10.17605/OSF.IO/CB7Z8},
	abstract = {Full and short paper submissions to the AGILE conference must include a Data and Software Availability sub-section as part of the Methods section. This document explains how to write that section and provides material for authors to increase computational reproducibility of their scholarly manuscripts. 
    Hosted on the Open Science Framework},
	language = {en},
	author = {N\"ust, Daniel and Ostermann, Frank and Sileryte, Rusne and Hofer, Barbara and Granell, Carlos and Teperek, Marta and Graser, Anita and Broman, Karl and Hettne, Kristina},
	year = {2019},
	organization = {OSF}
}

@misc{reproducible_agile,
  doi = {10.17605/OSF.IO/PHMCE},
  url = {https://reproducible-agile.github.io/},
  author = {N\"ust, Daniel and Ostermann, Frank and Sileryte, Rusne and Hofer, Barbara and Granell, Carlos and Teperek, Marta and Graser, Anita and Broman, Karl and Hettne, Kristina and Konkol, Markus},
  title = {{Reproducible Publications at AGILE Conferences}},
  publisher = {Open Science Framework},
  year = {2019}
}

@article{stodden_best_2014,
	title = {Best {Practices} for {Computational} {Science}: {Software} {Infrastructure} and {Environments} for {Reproducible} and {Extensible} {Research}},
	volume = {2},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2049-9647},
	shorttitle = {Best {Practices} for {Computational} {Science}},
	doi = {10.5334/jors.ay},
	abstract = {The goal of this article is to coalesce a discussion around best practices for scholarly research that utilizes computational methods, by providing a formalized set of best practice recommendations to guide computational scientists and other stakeholders wishing to disseminate reproducible research, facilitate innovation by enabling data and code re-use, and enable broader communication of the output of computational scientific research. Scholarly dissemination and communication standards are changing to reflect the increasingly computational nature of scholarly research, primarily to include the sharing of the data and code associated with published results. We also present these Best Practices as a living, evolving, and changing document at http://wiki.stodden.net/Best\_Practices.},
	language = {en},
	number = {1},
	journal = {Journal of Open Research Software},
	author = {Stodden, Victoria and Miguez, Sheila},
	year = {2014},
	keywords = {archiving, best practices, code sharing, computational science, data sharing, open science, reproducible research, scientific method, wiki},
	pages = {e21}
}

@article{brinckman_computing_2018,
	title = {Computing environments for reproducibility: {Capturing} the “{Whole} {Tale}”},
	issn = {0167-739X},
	shorttitle = {Computing environments for reproducibility},
	doi = {10.1016/j.future.2017.12.029},
	abstract = {The act of sharing scientific knowledge is rapidly evolving away from traditional articles and presentations to the delivery of executable objects that integrate the data and computational details (e.g., scripts and workflows) upon which the findings rely. This envisioned coupling of data and process is essential to advancing science but faces technical and institutional barriers. The Whole Tale project aims to address these barriers by connecting computational, data-intensive research efforts with the larger research process—transforming the knowledge discovery and dissemination process into one where data products are united with research articles to create “living publications” or tales. The Whole Tale focuses on the full spectrum of science, empowering users in the long tail of science, and power users with demands for access to big data and compute resources. We report here on the design, architecture, and implementation of the Whole Tale environment.},
	journal = {Future Generation Computer Systems},
	author = {Brinckman, Adam and Chard, Kyle and Gaffney, Niall and Hategan, Mihael and Jones, Matthew B. and Kowalik, Kacper and Kulasekaran, Sivakumar and Ludäscher, Bertram and Mecum, Bryce D. and Nabrzyski, Jarek and Stodden, Victoria and Taylor, Ian J. and Turk, Matthew J. and Turner, Kandace},
	year = {2018},
	keywords = {Code sharing, Data sharing, Living publications, Provenance, Reproducibility}
}

@article{marwick_computational_2017,
	title = {Computational {Reproducibility} in {Archaeological} {Research}: {Basic} {Principles} and a {Case} {Study} of {Their} {Implementation}},
	volume = {24},
	issn = {1573-7764},
	shorttitle = {Computational {Reproducibility} in {Archaeological} {Research}},
	doi = {10.1007/s10816-015-9272-9},
	abstract = {The use of computers and complex software is pervasive in archaeology, yet their role in the analytical pipeline is rarely exposed for other researchers to inspect or reuse. This limits the progress of archaeology because researchers cannot easily reproduce each other’s work to verify or extend it. Four general principles of reproducible research that have emerged in other fields are presented. An archaeological case study is described that shows how each principle can be implemented using freely available software. The costs and benefits of implementing reproducible research are assessed. The primary benefit, of sharing data in particular, is increased impact via an increased number of citations. The primary cost is the additional time required to enhance reproducibility, although the exact amount is difficult to quantify.},
	language = {en},
	number = {2},
	journal = {Journal of Archaeological Method and Theory},
	author = {Marwick, Ben},
	year = {2017},
	keywords = {Software engineering, Open science, Computer programming, Reproducible research, Australian archaeology},
	pages = {424--450}
}

@book{r_core_team_r:_2019,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2019}
}

@article{nosek_promoting_2015,
	title = {Promoting an open research culture},
	volume = {348},
	copyright = {Copyright © 2015, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aab2374},
	abstract = {Author guidelines for journals could help to promote transparency, openness, and reproducibility},
	language = {en},
	number = {6242},
	journal = {Science},
	author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. Levy and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
	month = jun,
	year = {2015},
	pmid = {26113702},
	pages = {1422--1425}
}

@article{perkel_make_2019,
	title = {Make code accessible with these cloud services},
	volume = {575},
	copyright = {2019 Nature},
	doi = {10.1038/d41586-019-03366-x},
	abstract = {Container platforms let researchers run each other’s software — and check the results.},
	language = {en},
	journal = {Nature},
	author = {Perkel, Jeffrey M.},
	month = nov,
	year = {2019},
	pages = {247--248}
}

@misc{the_turing_way_community_turing_2019,
	title = {The {Turing} {Way}: {A} {Handbook} for {Reproducible} {Data} {Science}},
	shorttitle = {The {Turing} {Way}},
	abstract = {Reproducible research is necessary to ensure that scientific work can be trusted. Funders and publishers are beginning to require that publications include access to the underlying data and the analysis code. The goal is to ensure that all results can be independently verified and built upon in future work. This is sometimes easier said than done. Sharing these research outputs means understanding data management, library sciences, software development, and continuous integration techniques: skills that are not widely taught or expected of academic researchers and data scientists. The Turing Way is a handbook to support students, their supervisors, funders and journal editors in ensuring that reproducible data science is "too easy not to do". It will include training material on version control, analysis testing, and open and transparent communication with future users, and build on Turing Institute case studies and workshops. This project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. Release log v0.0.4: Continuous integration chapter merged to master. v0.0.3: Reproducible environments chapter merged to master. v0.0.2: Version control chapter merged to master. v0.0.1: Reproducibility chapter merged to master.},
	publisher = {Zenodo},
	author = {{The Turing Way Community} and Becky Arnold and Louise Bowler and Sarah Gibson and Patricia Herterich and Rosie Higman and Anna Krystalli and Alexander Morley and Martin O'Reilly and Kirstie Whitaker},
	month = mar,
	year = {2019},
	doi = {10.5281/zenodo.3233986},
	annote = {This work was supported by The UKRI Strategic Priorities Fund under the EPSRC Grant EP/T001569/1, particularly the "Tools, Practices and Systems" theme within that grant, and by The Alan Turing Institute under the EPSRC grant EP/N510129/1.}
}

@article{foster_research_2018,
	title = {Research {Infrastructure} for the {Safe} {Analysis} of {Sensitive} {Data}},
	volume = {675},
	issn = {0002-7162},
	doi = {10.1177/0002716217742610},
	abstract = {To use administrative and other new data sources for the scientific study of human beings and human behavior, analysts need to be able both to connect to these new data and to deploy new methods for linking and analyzing the data. These efforts are often hindered by legal, technical, and operational difficulties. In this article, I examine how new digital research infrastructures can be used to reduce such barriers. Experiences with data stewardship in other scientific domains shows that appropriate infrastructure can enable the efficient, secure, and collaborative integration of domain expertise, data, and analysis capabilities. I review the state of the art in these areas and argue for the use of cloud-hosted enclaves as a safe interaction point for analysts, data, and software, and as a means of automating and thus professionalizing data stewardship processes.},
	language = {en},
	number = {1},
	journal = {The ANNALS of the American Academy of Political and Social Science},
	author = {Foster, Ian},
	month = jan,
	year = {2018},
	pages = {102--120}
}

@article{munafo_manifesto_2017,
	title = {A manifesto for reproducible science},
	volume = {1},
	copyright = {2017 Macmillan Publishers Limited},
	issn = {2397-3374},
	doi = {10.1038/s41562-016-0021},
	abstract = {Leading voices in the reproducibility landscape call for the adoption of measures to optimize key elements of the scientific process.},
	language = {en},
	number = {1},
	journal = {Nature Human Behaviour},
	author = {Munafò, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V. M. and Button, Katherine S. and Chambers, Christopher D. and Sert, Nathalie Percie du and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J. and Ioannidis, John P. A.},
	month = jan,
	year = {2017},
	pages = {1--9}
}

@article{ram_git_2013,
	title = {Git can facilitate greater reproducibility and increased transparency in science},
	volume = {8},
	issn = {1751-0473},
	doi = {10.1186/1751-0473-8-7},
	abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.},
	number = {1},
	journal = {Source Code for Biology and Medicine},
	author = {Ram, Karthik},
	month = feb,
	year = {2013},
	pages = {7}
}

@article{hrynaszkiewicz_publishers_2019,
	title = {Publishers’ {Responsibilities} in {Promoting} {Data} {Quality} and {Reproducibility}},
	doi = {10.1007/164_2019_290},
	abstract = {Scholarly publishers can help to increase data quality and reproducible research by promoting transparency and openness. Increasing transparency can be achieved by publishers in six key areas: (1)...},
	language = {en},
	author = {Hrynaszkiewicz, Iain},
	year = {2019},
	pages = {1--30}
}

@incollection{buckheit_wavelab_1995,
	series = {Lecture {Notes} in {Statistics}},
	title = {{WaveLab} and {Reproducible} {Research}},
	copyright = {©1995 Springer-Verlag New York},
	isbn = {978-0-387-94564-4 978-1-4612-2544-7},
	abstract = {Wavelab is a library of wavelet-packet analysis, cosine-packet analysis and matching pursuit. The library is available free of charge over the Internet. Versions are provided for Macintosh, UNIX and Windows machines. Wavelab makes available, in one package, all the code to reproduce all the figures in our published wavelet articles. The interested reader can inspect the source code to see exactly what algorithms were used, how parameters were set in producing our figures, and can then modify the source to produce variations on our results. WAVELAB has been developed, in part, because of exhortations by Jon Claerbout of Stanford that computational scientists should engage in “really reproducible” research.},
	language = {en},
	number = {103},
	booktitle = {Wavelets and {Statistics}},
	publisher = {Springer New York},
	author = {Buckheit, Jonathan B. and Donoho, David L.},
	editor = {Antoniadis, Anestis and Oppenheim, Georges},
	year = {1995},
	doi = {10.1007/978-1-4612-2544-7_5},
	keywords = {Probability Theory and Stochastic Processes},
	pages = {55--81}
}

@Manual{zen4r,
  title = {zen4R: Interface to 'Zenodo' REST API},
  author = {Emmanuel Blondel},
  year = {2020},
  note = {R package version 0.4-2},
  url = {https://CRAN.R-project.org/package=zen4R},
}

@misc{codecheck_register_sep2020,
  author       = {Daniel N\"ust and
                  Stephen Eglen and
                  Iain Davies},
  title        = {{codecheckers/register: CODECHECK Register Deposit September 2020}},
  month        = sep,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {2020-09},
  doi          = {10.5281/zenodo.4059768},
  url          = {https://codecheck.org.uk/register/}
}

@misc{codecheck_register_jan2021,
  author       = {Daniel N\"ust and
                  Stephen Eglen and
                  Iain Davies},
  title        = {{codecheckers/register: CODECHECK Register Deposit January 2021}},
  month        = sep,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {2020-09},
  doi          = {10.5281/zenodo.4486559},
  url          = {https://codecheck.org.uk/register/}
}

@misc{stark_before_2018,
	type = {News},
	title = {Before reproducibility must come preproducibility},
	copyright = {2018 Nature},
	abstract = {Instead of arguing about whether results hold up, let’s push to provide enough information for others to repeat the experiments, says Philip Stark.},
	language = {EN},
	journal = {Nature},
	author = {Stark, Philip B.},
	month = may,
	year = {2018},
	doi = {10.1038/d41586-018-05256-0}
}

@article{tennant_limitations_2020,
	title = {The limitations to our understanding of peer review},
	volume = {5},
	issn = {2058-8615},
	doi = {10.1186/s41073-020-00092-1},
	abstract = {Peer review is embedded in the core of our knowledge generation systems, perceived as a method for establishing quality or scholarly legitimacy for research, while also often distributing academic prestige and standing on individuals. Despite its critical importance, it curiously remains poorly understood in a number of dimensions. In order to address this, we have analysed peer review to assess where the major gaps in our theoretical and empirical understanding of it lie. We identify core themes including editorial responsibility, the subjectivity and bias of reviewers, the function and quality of peer review, and the social and epistemic implications of peer review. The high-priority gaps are focused around increased accountability and justification in decision-making processes for editors and developing a deeper, empirical understanding of the social impact of peer review. Addressing this at the bare minimum will require the design of a consensus for a minimal set of standards for what constitutes peer review, and the development of a shared data infrastructure to support this. Such a field requires sustained funding and commitment from publishers and research funders, who both have a commitment to uphold the integrity of the published scholarly record. We use this to present a guide for the future of peer review, and the development of a new research discipline based on the study of peer review.},
	number = {1},
	journal = {Research Integrity and Peer Review},
	author = {Tennant, Jonathan P. and Ross-Hellauer, Tony},
	month = apr,
	year = {2020},
	pages = {6}
}

% https://twitter.com/hertzpodcast/status/1334155945652449280
@article{everythinghertz97,
  author={Quintana, Daniel and Heathers, James},
  title={{Everything Hertz} 97: Slow science},
  journal={Open Science Framework},
  organization={Everything Hertz},
  month={Dec},
  year=2019,
  series={Everything Hertz},
  doi = {10.17605/OSF.IO/XEU42},
}
%  note={Sports analogy mentioned by Dan Quintana at the 55:15 minute mark.}

@article{everythinghertz123,
  author={Quintana, Daniel and Heathers, James},
  title={{Everything Hertz} 123: Authenticated anonymity (with {Michael} {Eisen})},
  journal={Open Science Framework},
  organization={Everything Hertz},
  month={Jan},
  year=2020,
  series={Everything Hertz},
  doi = {10.17605/OSF.IO/9CFTX}
}

@article{konkol_publishing_2020,
	title = {Publishing computational research - a review of infrastructures for reproducible and transparent scholarly communication},
	volume = {5},
	issn = {2058-8615},
	doi = {10.1186/s41073-020-00095-y},
	abstract = {The trend toward open science increases the pressure on authors to provide access to the source code and data they used to compute the results reported in their scientific papers. Since sharing materials reproducibly is challenging, several projects have developed solutions to support the release of executable analyses alongside articles.},
	number = {1},
	journal = {Research Integrity and Peer Review},
	author = {Konkol, Markus and N\"ust, Daniel and Goulier, Laura},
	month = jul,
	year = {2020},
	pages = {10}
}

@article{auer_reproducibility_2020,
	title = {Reproducibility for everyone: a community-led initiative with global reach in reproducible research training},
	abstract = {Reproducibility is a cornerstone of the scientific method and sets apart science from pseudoscience. Unfortunately, a majority of scientists have experienced difficulties in reproducing their own or someone else’s results. This inability to confirm scientific findings negatively impacts individual scientists, funding bodies, academic journals, pharmaceutical drug development and the public’s perception of science. Factors causing irreproducible results can arise from nearly every aspect of the scientific process, and typically reflect a lack of in-depth training in reproducible research practices. Here, we present the Reproducibility for Everyone (R4E) initiative, a collaboration between researchers from diverse scientific disciplines and industry partners who aspire to promote open and reproducible research practices. We have developed a customizable workshop series targeting researchers at all levels and across disciplines. Our workshop series covers the conceptual framework of reproducible research practices followed by an overview of actionable research practices. To date, we have reached more than 2000 researchers through over 25 workshops held at international conferences and local meetings. By incorporating further contributions from the scientific community, we hope to expand this valuable resource for teaching transparent and reproducible research practices. Our initiative demonstrates how a shared set of materials may form the basis for a global initiative to improve reproducibility in science. The workshop materials, including accompanying resources, are available under a CC-BY 4.0 license at www.repro4everyone.org.},
	journal = {OSF Preprints},
	author = {Auer, Susann and Haelterman, Nele and Weissgerber, Tracey and Erlich, Jeffrey C. and Susilaradeya, Damar and Julkowska, Magdalena and Gazda, Małgorzata Anna and Abitua, Angela and Niraulu, Anzela and Shah, Aparna and Clyburne-Sherin, April and Guiquel, Benoit and Alicea, Bradly and LaManna, Caroline and Ganguly, Diep and Perkins, Eric J. and Jambor, Helena and Li, Ian Man Ho and Tsang, Jennifer and Kamens, Joanne and Teytelman, Lenny and Paul, Mariella and Phuyal, Santosh and Schmelling, Nicolas and Crisp, Peter and Sarabipour, Sarvenaz and Roy, Sonali and Bachle, Susanna and Tran, MR Tuan Khoi and Ford, Tyler and Steeves, Vicky and Ilangovan, Vinodh and Schwessinger, Benjamin and Jadavji, Nafisa},
	month = oct,
	year = {2020},
	doi = {10.31219/osf.io/dxw67}
}

@article{fitzgibbon_brewing_2020,
	title = {Brewing up a storm: developing {Open} {Research} culture through {ReproducibiliTea}},
	copyright = {cc\_by\_4},
	shorttitle = {Brewing up a storm},
	abstract = {ReproducibiliTea Reading is a group of researchers and students who meet regularly to discuss Open Research practice. Our aim is to reduce the perceived costs of adopting open and reproducible practices by increasing Open Research literacy. We have developed our technical skills and promoted open practices that have been taken up in our research. We are also exploring ways in which Open Research objectives can be integrated into student learning activities and researcher incentives.},
	language = {en},
	note = {Central Archive at the University of Reading},
	journal = {Report},
	author = {Fitzgibbon, Lily and Brady, Daniel and Haffey, Anthony and Kurdi, Vanessa and Lau, Johnny and Raw, Jasmine and Roesch, Etienne and Williams, Brendan},
	year = {2020},
	doi = {10.17864/1926.92781}
}

@article{greenwood_how_2015,
	title = {How to spot a statistical problem: advice for a non-statistical reviewer},
	volume = {13},
	issn = {1741-7015},
	shorttitle = {How to spot a statistical problem},
	doi = {10.1186/s12916-015-0510-5},
	abstract = {Statistical analyses presented in general medical journals are becoming increasingly sophisticated. BMC Medicine relies on subject reviewers to indicate when a statistical review is required. We consider this policy and provide guidance on when to recommend a manuscript for statistical evaluation. Indicators for statistical review include insufficient detail in methods or results, some common statistical issues and interpretation not based on the presented evidence. Reviewers are required to ensure that the manuscript is methodologically sound and clearly written. Within that context, they are expected to provide constructive feedback and opinion on the statistical design, analysis, presentation and interpretation. If reviewers lack the appropriate background to positively confirm the appropriateness of any of the manuscript’s statistical aspects, they are encouraged to recommend it for expert statistical review.},
	number = {1},
	journal = {BMC Medicine},
	author = {Greenwood, Darren C. and Freeman, Jennifer V.},
	month = nov,
	year = {2015},
	keywords = {Completeness of reporting, Editorial policy, Peer review, Presentation, Professional competence, Publishing, Recommendations to reviewers, Reporting guidelines, Statistics},
	pages = {270}
}

@article{petrovecki_role_2009,
	title = {The role of statistical reviewer in biomedical scientific journal},
	volume = {19},
	doi = {10.11613/BM.2009.020},
	language = {en},
	number = {3},
	journal = {Biochemia Medica},
	author = {Petrovečki, Mladen},
	month = oct,
	year = {2009},
	publisher = {Croatian Society of Medical Biochemistry and Laboratory Medicine},
	pages = {223--230}
}

@article{shannon_opening_2018,
	title = {Opening {GIScience}: {A} process-based approach},
	volume = {32},
	issn = {1365-8816},
	shorttitle = {Opening {GIScience}},
	doi = {10.1080/13658816.2018.1464167},
	abstract = {Many scholars have demonstrated growing interest in GIScience in recent years, including use of open data portals, shared code and options for open access publication. These practices have made both research and data more transparent and accessible for a broad audience. This research may be open only in a limited sense for populations without expertise in the technology and methods undergirding these data. Based on two case studies using RStudio’s Shiny web platform, we argue that a process-based approach focusing on how analysis is opened throughout the research process provides a supplementary way to define and reflect upon public facing geographic research. Reflecting upon decisions we made at key points in each case study project, we identify four key tensions inherent to work in open GIScience: standardized vs. flexible tools, expert vs. community-led design, single vs. multiple audiences and established vs. emerging metrics.},
	number = {10},
	journal = {International Journal of Geographical Information Science},
	author = {Shannon, Jerry and Walker, Kyle},
	month = oct,
	year = {2018},
	keywords = {Open source, census data, internet GIS, public participation GIS},
	pages = {1911--1926}
}

@article{oloughlin_data_2015,
	title = {Data ethics: {Pluralism}, replication, conflicts of interest, and standards in {Political} {Geography}},
	volume = {44},
	issn = {0962-6298},
	shorttitle = {Data ethics},
	doi = {10.1016/j.polgeo.2014.11.001},
	language = {en},
	journal = {Political Geography},
	author = {O'Loughlin, John and Raento, Pauliina and Sharp, Joanne P. and Sidaway, James D. and Steinberg, Philip E.},
	month = jan,
	year = {2015},
	pages = {A1--A3}
}

@article{harris_more_2017,
	title = {More bark than bytes? {Reflections} on 21+ years of geocomputation},
	volume = {44},
	issn = {2399-8083},
	shorttitle = {More bark than bytes?},
	doi = {10.1177/2399808317710132},
	abstract = {This year marks the 21st anniversary of the International GeoComputation Conference Series. To celebrate the occasion, Environment and Planning B invited some members of the geocomputational community to reflect on its achievements, some of the unrealised potential, and to identify some of the on-going challenges.},
	language = {en},
	number = {4},
	journal = {Environment and Planning B: Urban Analytics and City Science},
	author = {Harris, Richard and O’Sullivan, David and Gahegan, Mark and Charlton, Martin and Comber, Lex and Longley, Paul and Brunsdon, Chris and Malleson, Nick and Heppenstall, Alison and Singleton, Alex and Arribas-Bel, Daniel and Evans, Andy},
	month = jul,
	year = {2017},
	pages = {598--617}
}

                
@misc{munafo_what_2020,
	title = {What you need to know about how coronavirus is changing science},
	url = {http://theconversation.com/what-you-need-to-know-about-how-coronavirus-is-changing-science-137641},
	abstract = {Scientific results are being rushed out quicker than ever to fight coronavirus. Here's what you need to know about preprints, peer review and the difference between the two.},
	language = {en},
	date = {2020-05-05},
	year = {2020},
	month = {May},
	urldate = {2020-12-07},
	journal = {The Conversation},
	author = {Munafo, Marcus}
}

@techreport{stodden_setting_2013,
	title = {Setting the {Default} to {Reproducible}: {Reproducibility} in {Computational} and {Experimental} {Mathematics}},
	url = {https://icerm.brown.edu/topical_workshops/tw12-5-rcem/icerm_report.pdf},
	abstract = {In addition to advancing research and discovery in pure and applied mathematics, computation is pervasive across the sciences and now computational research results are more crucial than ever for public policy, risk management, and national security. Reproducibility of carefully documented experiments is a cornerstone of the scientific method, and yet is often lacking in computational mathematics, science, and engineering. Setting and achieving appropriate standards for reproducibility in computation poses a number of interesting technological and social challenges. The purpose of this workshop is to discuss aspects of reproducibility most relevant to the mathematical sciences among researchers from pure and applied mathematics from academics and other settings, together with interested parties from funding agencies, national laboratories, professional societies, and publishers. This will be a working workshop, with relatively few talks and dedicated time for breakout group discussions on the current state of the art and the tools, policies, and infrastructure that are needed to improve the situation. The groups will be charged with developing guides to current best practices and/or white papers on desirable advances.},
	urldate = {2020-12-08},
	institution = {The Institute for Computational and Experimental Research in Mathematics},
	author = {Stodden, Victoria and Bailey, David H. and Borwein, Jonathan and LeVeque, Randall J. and Rider, Bill and Stein, William},
	month = feb,
	year = {2013},
}
% note = {Workshop website with full list of workshop participants: https://icerm.brown.edu/topical\_workshops/tw12-5-rcem/
This report was developed collaboratively by the ICERM workshop participants, and compiled and edited by the organizers.}

@article{fyfe_mission_2019,
	title = {Mission or money?},
	issn = {2387-3086},
	doi = {10.7557/5.4963},
	journal = {Septentrio Conference Series},
	author = {Fyfe, Aileen},
	month = sep,
	year = {2019},
	note = {Keynote at 14th {Munin} {Conference} on {Scholarly} {Publishing} 2019}
}

@misc{earthcube_new_2020,
	title = {New {EarthCube} {Peer}-{Reviewed} {Jupyter} {Notebooks} {Now} {Available}},
	url = {https://www.earthcube.org/notebooks},
	abstract = {A novel element of the EarthCube 2020 Annual Conference was a call for notebooks, which led to twelve peer-reviewed Jupyter notebooks that encompass an array of geoscience data tools, software, services, and libraries. Each notebook was reviewed by scholars within the geoscience and cyberinfrastructure community at the EarthCube 2020 Annual Conference.

These notebooks are now available on GitHub for interested researchers to view and execute, and they will soon be published in the Earth and Space Science Open Archive (ESSOAr).},
	language = {en},
	urldate = {2020-12-09},
	journal = {EarthCube},
	author = {{EarthCube}},
	year = {2020}
}

@article{chambers_verification_2020,
	title = {Verification {Reports}: {A} new article type at {Cortex}},
	volume = {129},
	issn = {0010-9452},
	shorttitle = {Verification {Reports}},
	doi = {10.1016/j.cortex.2020.04.020},
	language = {en},
	journal = {Cortex},
	author = {Chambers, Christopher D.},
	month = aug,
	year = {2020},
	pages = {A1--A3}
}

@article{benjamin-chung_internal_2020,
	title = {Internal replication of computational workflows in scientific research},
	volume = {4},
	issn = {2572-4754},
	doi = {10.12688/gatesopenres.13108.2},
	language = {en},
	journal = {Gates Open Research},
	author = {Benjamin-Chung, Jade and Colford, Jr., John M. and Mertens, Andrew and Hubbard, Alan E. and Arnold, Benjamin F.},
	month = jun,
	year = {2020},
	pages = {17}
}

@article{gavish_universal_2011,
	series = {Proceedings of the {International} {Conference} on {Computational} {Science}, {ICCS} 2011},
	title = {A {Universal} {Identifier} for {Computational} {Results}},
	volume = {4},
	issn = {1877-0509},
	doi = {10.1016/j.procs.2011.04.067},
	abstract = {We present a discipline for verifiable computational scienti\_c research. Our discipline revolves around three simple new concepts — verifiable computational result (VCR), VCR repository and Verifiable Result Identifier (VRI). These are web- and cloud-computing oriented concepts, which exploit today's web infrastructure to achieve standard, simple and automatic reproducibility in computational scientific research. The VCR discipline requires very slight modifications to the way researchers already conduct their computational research and authoring, and to the way publishers manage their content. In return, the discipline marks a significant step towards delivering on the long-anticipated promises of making scientific computation truly reproducible. A researcher practicing this discipline in everyday work produces computational scripts and word processor files that look very much like those they already produce today, but in which a few lines change very subtly and naturally. Those scripts produce a stream of verifiable results, which are the same tables, figures, charts and datasets the researcher traditionally would have produced, but which are watermarked for permanent identification by a VRI, and are automatically and permanently stored in a VCR repository. In a scientific community practicing Verifiable Computational Research, exchange of both ideas and data involves exchanging result identifiers—VRIs—rather than exchanging files. These identifiers are controlled, trusted and automatically generated strings that point to publicly available result as it was originally created by the computational process itself. When a verifiable result is included in a publication, its identifier can be used by any reader with a web browser to locate, browse and, where appropriate, re-execute the computation that produced the result. Journal readers can therefore scrutinize, dispute, understand and eventually trust these computational results, all to an extent impossible through textual explanations that constitute the core of scientific publications to date. In addition, the result identi\_er can be used by subsequent computations to locate and retrieve both the published result (in graphical or numerical form) and the original datasets used by its generating computation. Colleagues can thus cite and import data into their own computations, just as traditional publications allow them to cite and import ideas. We describe an existing software implementation of the Verifiable Computational Research discipline, and argue that it solves many of the crucial problems commonly facing computer-based and computer-aided research in various scientific fields. Our system is secure, naturally adapted to large-scale and cloud computations and to modern massive data analysis, yet places effectively no additional workload on either the researcher or the publisher.},
	language = {en},
	journal = {Procedia Computer Science},
	author = {Gavish, Matan and Donoho, David},
	month = jan,
	year = {2011},
	keywords = {computation chronicle, reproducible research, VCR repository, verifiable computational research, verifiable result, verifiable result identifier},
	pages = {637--647}
}

@article{petre_code_2014,
	title = {Code {Review} {For} and {By} {Scientists}},
	url = {http://arxiv.org/abs/1407.5648},
	abstract = {We describe two pilot studies of code review by and for scientists. Our principal findings are that scientists are enthusiastic, but need to be shown code review in action, and that just-in-time review of small code changes is more likely to succeed than large-scale end-of-work reviews.},
	urldate = {2020-12-10},
	journal = {arXiv:1407.5648 [cs]},
	author = {Petre, Marian and Wilson, Greg},
	month = sep,
	year = {2014},
	note = {arXiv: 1407.5648},
	keywords = {Computer Science - Software Engineering},
	annote = {Comment: 4 pages}
}

@article{ross-hellauer_guidelines_2019,
	title = {Guidelines for open peer review implementation},
	volume = {4},
	issn = {2058-8615},
	doi = {10.1186/s41073-019-0063-9},
	abstract = {Open peer review (OPR) is moving into the mainstream, but it is often poorly understood and surveys of researcher attitudes show important barriers to implementation. As more journals move to implement and experiment with the myriad of innovations covered by this term, there is a clear need for best practice guidelines to guide implementation. This brief article aims to address this knowledge gap, reporting work based on an interactive stakeholder workshop to create best-practice guidelines for editors and journals who wish to transition to OPR. Although the advice is aimed mainly at editors and publishers of scientific journals, since this is the area in which OPR is at its most mature, many of the principles may also be applicable for the implementation of OPR in other areas (e.g., books, conference submissions).},
	number = {1},
	journal = {Research Integrity and Peer Review},
	author = {Ross-Hellauer, Tony and Görögh, Edit},
	month = feb,
	year = {2019},
	keywords = {Guidelines, Open peer review, Open science, Peer review, Scholarly publishing},
	pages = {4}
}

@article{heroux_editorial_2015,
	title = {Editorial: {ACM} {TOMS} {Replicated} {Computational} {Results} {Initiative}},
	volume = {41},
	issn = {0098-3500},
	shorttitle = {Editorial},
	doi = {10.1145/2743015},
	abstract = {The scientific community relies on the peer review process for assuring the quality of published material, the goal of which is to build a body of work we can trust. Computational journals such as the ACM Transactions on Mathematical Software (TOMS) use this process for rigorously promoting the clarity and completeness of content, and citation of prior work. At the same time, it is unusual to independently confirm computational results. ACM TOMS has established a Replicated Computational Results (RCR) review process as part of the manuscript peer review process. The purpose is to provide independent confirmation that results contained in a manuscript are replicable. Successful completion of the RCR process awards a manuscript with the Replicated Computational Results Designation. This issue of ACM TOMS contains the first [Van Zee and van de Geijn 2015] of what we anticipate to be a growing number of articles to receive the RCR designation, and the related RCR reviewer report [Willenbring 2015]. We hope that the TOMS RCR process will serve as a model for other publications and increase the confidence in and value of computational results in TOMS articles.},
	number = {3},
	journal = {ACM Transactions on Mathematical Software},
	author = {Heroux, Michael A.},
	month = jun,
	year = {2015},
	keywords = {publication, Replicated computational results, reproducibility, validation},
	pages = {13:1--13:5}
}

@article{perkel_pioneering_2019-1,
	title = {Pioneering ‘live-code’ article allows scientists to play with each other’s results},
	volume = {567},
	copyright = {2020 Nature},
	doi = {10.1038/d41586-019-00724-7},
	abstract = {The goal is to use software functionality to make science easier to test, reproduce and build on.},
	language = {en},
	number = {7746},
	journal = {Nature},
	author = {Perkel, Jeffrey M.},
	month = feb,
	year = {2019},
	publisher = {Nature Publishing Group},
	pages = {17--18}
}

@article{beaulieu-jones_reproducibility_2017-1,
	title = {Reproducibility of computational workflows is automated using continuous analysis},
	volume = {35},
	copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1696},
	doi = {10.1038/nbt.3780},
	abstract = {The application of continuous integration, an approach common in software development, enables the automatic reproduction of computational analyses.},
	language = {en},
	number = {4},
	journal = {Nature Biotechnology},
	author = {Beaulieu-Jones, Brett K. and Greene, Casey S.},
	month = apr,
	year = {2017},
	publisher = {Nature Publishing Group},
	pages = {342--346}
}

@article{nust_opening_2017,
	title = {Opening the {Publication} {Process} with {Executable} {Research} {Compendia}},
	volume = {23},
	issn = {1082-9873},
	doi = {10.1045/january2017-nuest},
	language = {en},
	number = {1/2},
	journal = {D-Lib Magazine},
	author = {Nst, Daniel and Konkol, Markus and Pebesma, Edzer and Kray, Christian and Schutzeichel, Marc and Przibytzin, Holger and Lorenz, Jörg},
	month = jan,
	year = {2017}
}

@article{roesch_new_2020,
	title = {New journal for reproduction and replication results},
	volume = {581},
	copyright = {2020 Nature},
	doi = {10.1038/d41586-020-01328-2},
	abstract = {Discover the world’s best science and medicine  {\textbar} Nature.com},
	language = {en},
	number = {7806},
	journal = {Nature},
	author = {Roesch, Etienne B. and Rougier, Nicolas},
	month = may,
	year = {2020},
	publisher = {Nature Publishing Group},
	pages = {30--30}
}

@article{stagge_assessing_2019,
	title = {Assessing data availability and research reproducibility in hydrology and water resources},
	volume = {6},
	copyright = {2019 The Author(s)},
	issn = {2052-4463},
	doi = {10.1038/sdata.2019.30},
	abstract = {There is broad interest to improve the reproducibility of published research. We developed a survey tool to assess the availability of digital research artifacts published alongside peer-reviewed journal articles (e.g. data, models, code, directions for use) and reproducibility of article results. We used the tool to assess 360 of the 1,989 articles published by six hydrology and water resources journals in 2017. Like studies from other fields, we reproduced results for only a small fraction of articles (1.6\% of tested articles) using their available artifacts. We estimated, with 95\% confidence, that results might be reproduced for only 0.6\% to 6.8\% of all 1,989 articles. Unlike prior studies, the survey tool identified key bottlenecks to making work more reproducible. Bottlenecks include: only some digital artifacts available (44\% of articles), no directions (89\%), or all artifacts available but results not reproducible (5\%). The tool (or extensions) can help authors, journals, funders, and institutions to self-assess manuscripts, provide feedback to improve reproducibility, and recognize and reward reproducible articles as examples for others.},
	language = {en},
	number = {1},
	journal = {Scientific Data},
	author = {Stagge, James H. and Rosenberg, David E. and Abdallah, Adel M. and Akbar, Hadia and Attallah, Nour A. and James, Ryan},
	month = feb,
	year = {2019},
	publisher = {Nature Publishing Group},
	pages = {190030}
}

@article{nust_improving_2020,
	title = {Improving reproducibility of geospatial conference papers – lessons learned from a first implementation of reproducibility reviews},
	issn = {2387-3086},
	doi = {10.7557/5.5601},
	language = {en},
	journal = {Septentrio Conference Series},
	author = {N\"ust, Daniel and Ostermann, Frank and Granell, Carlos and Kmoch, Alexander},
	month = sep,
	year = {2020},
}

@incollection{Rosenthal2016b,
	address = {Dagstuhl, Germany},
	series = {Dagstuhl reports},
	title = {Incentives and barriers to reproducibility: {Investments} and returns},
	volume = {6},
	doi = {10.4230/DagRep.6.1.108},
	number = {1},
	booktitle = {Reproducibility of data-oriented experiments in e-{Science}},
	publisher = {Schloss Dagstuhl–Leibniz-Zentrum fuer Informatik},
	author = {Rosenthal, Paul and Mayer, Rudolf and Page, Kevin and Stotzka, Rainer and Viegas, Evelyne},
	editor = {Freire, Juliana and Fuhr, Norbert and Rauber, Andreas},
	month = jan,
	year = {2016},
	note = {ISSN: 2192-5283},
	pages = {148--151}
}

@misc{chambers_registered_2019,
	title = {Registered {Reports}},
	url = {https://osf.io/mvdyq/},
	language = {en},
	urldate = {2020-12-10},
	author = {Chambers, Chris},
	month = jun,
	year = {2019},
	note = {Publisher: OSF}
}

@inproceedings{tenorio-fornes_towards_2019,
	title = {Towards a {Decentralized} {Process} for {Scientific} {Publication} and {Peer} {Review} using {Blockchain} and {IPFS}},
	copyright = {Attribution-NonCommercial-NoDerivatives 4.0 International},
	isbn = {978-0-9981331-2-6},
	doi = {10.24251/HICSS.2019.560},
	abstract = {The current processes of scientific publication and peer review raise concerns around fairness, quality, performance, cost, and accuracy. The Open Access movement has been unable to fulfill all its promises, and a few middlemen publishers can still impose policies and concentrate profits. This paper, using emerging distributed technologies such as Blockchain and IPFS, proposes a decentralized publication system for open science. The proposed system would provide (1) a distributed reviewer reputation system, (2) an Open Access by-design infrastructure, and (3) transparent governance processes. A survey is used to evaluate the problems, proposed solutions and possible adoption resistances, while a working prototype serves as a proof-of-concept. Additionally, the paper discusses the implementation, in a distributed context, of different privacy settings for both open peer review and reputation systems, introducing a novel approach supporting both anonymous and accountable reviews. The paper concludes reviewing the open challenges of this ambitious proposal.},
	language = {eng},
	author = {Tenorio-Fornés, Antonio and Jacynycz, Viktor and Llop-Vila, David and Sánchez-Ruiz, Antonio and Hassan, Samer},
	month = jan,
	year = {2019},
	note = {Accepted: 2019-01-03T00:29:12Z}
}

@article{noauthor_research_2020,
	title = {Research, reuse, repeat},
	volume = {2},
	copyright = {2020 Springer Nature Limited},
	issn = {2522-5839},
	doi = {10.1038/s42256-020-00277-9},
	abstract = {A research paper makes the most impact when its methods, data and code are available for others to use and build on. We highlight the benefits of good sharing practices with a new type of article, reusability reports.},
	language = {en},
	number = {12},
	journal = {Nature Machine Intelligence},
	month = dec,
	year = {2020},
	pages = {729--729}
}

@article{rosenberg_next_2020,
	title = {The {Next} {Frontier}: {Making} {Research} {More} {Reproducible}},
	volume = {146},
	copyright = {©2020 American Society of Civil Engineers},
	issn = {1943-5452},
	shorttitle = {The {Next} {Frontier}},
	doi = {10.1061/(ASCE)WR.1943-5452.0001215},
	language = {EN},
	number = {6},
	journal = {Journal of Water Resources Planning and Management},
	author = {Rosenberg, David E. and Filion, Yves and Teasley, Rebecca and Sandoval-Solis, Samuel and Hecht, Jory S. and van Zyl, Jakobus E. and McMahon, George F. and Horsburgh, Jeffery S. and Kasprzyk, Joseph R. and Tarboton, David G.},
	month = jun,
	year = {2020},
	publisher = {American Society of Civil Engineers},
	pages = {01820002}
}

@article{christian_journal_2020,
	title = {Journal data policies: {Exploring} how the understanding of editors and authors corresponds to the policies themselves},
	volume = {15},
	issn = {1932-6203},
	shorttitle = {Journal data policies},
	doi = {10.1371/journal.pone.0230281},
	abstract = {Despite the increase in the number of journals issuing data policies requiring authors to make data underlying reporting findings publicly available, authors do not always do so, and when they do, the data do not always meet standards of quality that allow others to verify or extend published results. This phenomenon suggests the need to consider the effectiveness of journal data policies to present and articulate transparency requirements, and how well they facilitate (or hinder) authors’ ability to produce and provide access to data, code, and associated materials that meet quality standards for computational reproducibility. This article describes the results of a research study that examined the ability of journal-based data policies to: 1) effectively communicate transparency requirements to authors, and 2) enable authors to successfully meet policy requirements. To do this, we conducted a mixed-methods study that examined individual data policies alongside editors’ and authors’ interpretation of policy requirements to answer the following research questions. Survey responses from authors and editors along with results from a content analysis of data policies found discrepancies among editors’ assertion of data policy requirements, authors’ understanding of policy requirements, and the requirements stated in the policy language as written. We offer explanations for these discrepancies and offer recommendations for improving authors’ understanding of policies and increasing the likelihood of policy compliance.},
	language = {en},
	number = {3},
	journal = {PLOS ONE},
	author = {Christian, Thu-Mai and Gooch, Amanda and Vision, Todd and Hull, Elizabeth},
	month = mar,
	year = {2020},
	publisher = {Public Library of Science},
	keywords = {Data management, Language, Medicine and health sciences, Open science, Reproducibility, Science policy, Social policy, Surveys},
	pages = {e0230281}
}

@ARTICLE{Vines2014-hf,
  title    = "The availability of research data declines rapidly with article
              age",
  author   = "Vines, Timothy H and Albert, Arianne Y K and Andrew, Rose L and
              D{\'e}barre, Florence and Bock, Dan G and Franklin, Michelle T
              and Gilbert, Kimberly J and Moore, Jean-S{\'e}bastien and Renaut,
              S{\'e}bastien and Rennison, Diana J",
  abstract = "Policies ensuring that research data are available on public
              archives are increasingly being implemented at the government
              [1], funding agency [2-4], and journal [5, 6] level. These
              policies are predicated on the idea that authors are poor
              stewards of their data, particularly over the long term [7], and
              indeed many studies have found that authors are often unable or
              unwilling to share their data [8-11]. However, there are no
              systematic estimates of how the availability of research data
              changes with time since publication. We therefore requested data
              sets from a relatively homogenous set of 516 articles published
              between 2 and 22 years ago, and found that availability of the
              data was strongly affected by article age. For papers where the
              authors gave the status of their data, the odds of a data set
              being extant fell by 17\% per year. In addition, the odds that we
              could find a working e-mail address for the first, last, or
              corresponding author fell by 7\% per year. Our results reinforce
              the notion that, in the long term, research data cannot be
              reliably preserved by individual researchers, and further
              demonstrate the urgent need for policies mandating data sharing
              via public archives.",
  journal  = "Curr. Biol.",
  volume   =  24,
  number   =  1,
  pages    = "94--97",
  month    =  jan,
  year     =  2014,
  issn     = "0960-9822, 1879-0445",
  pmid     = "24361065",
  doi      = "10.1016/j.cub.2013.11.014"
}

@article{cert-2020-024,
  doi = {10.5281/zenodo.4310025},
  author = {Stephen J. Eglen},
  title = {{CODECHECK} Certificate 2020-024},
  publisher = {Zenodo},
  journal = {Zenodo},
  year = {2020}
}

@article{vieira_driftage_2020,
	title = {Driftage: a multi-agent system for concept drift detection and an application on electromyography},
	issn = {2047-217X},
	url = {https://github.com/dmvieira/driftage},
	number = {under review},
	journal = {Gigascience},
	author = {Vieira, Diogo Munaro and Fernandes, Chrystinne and Lucena, Carlos and Lifschitz, Sérgio},
	year = {2020}
}

@article{cert-2020-025,
  doi = {10.5281/zenodo.4279275},
  author = {Daniel N\"ust},
  title = {{CODECHECK} Certificate 2020-025},
  publisher = {Zenodo},
  journal = {Zenodo},
  year = {2020}
}

@article{carrer_application_2021,
	title = {The application of {Local} {Indicators} for {Categorical} {Data} ({LICD}) to explore spatial dependence in archaeological spaces},
	volume = {126},
	issn = {0305-4403},
	doi = {10.1016/j.jas.2020.105306},
	abstract = {Global and local analyses of spatial autocorrelation are commonplace in spatial archaeology. However, they are exclusively focused on continuous numerical parameters, even though logical (presence/absence) and categorical parameters are equally frequent in archaeological research. Global tests of spatial dependence for categorical data are routinely used in other fields, and local versions of these tests (known as LICD) have recently been developed. This paper provides a detailed description of such methods, and presents the first adaptation and application of LICD to archaeological data. Different LICD versions have been tested on two case-studies: (a) an archaeological grid, with object presence or absence recorded for each cell; (b) Historic Landscape Characterisation, with the origin of character types (mediaeval, post-mediaeval or modern) recorded for each region. These examples seek to showcase and promote the use of LICD in landscape and intra-site archaeology.},
	language = {en},
	journal = {Journal of Archaeological Science},
	author = {Carrer, Francesco and Kossowski, Tomasz M. and Wilk, Justyna and Pietrzak, Michał B. and Bivand, Roger S.},
	month = feb,
	year = {2021},
	keywords = {Join-count statistics, LICD, Local autocorrelation, Regular and irregular lattice, Spatial analysis},
	pages = {105306}
}

@article{menke_rigor_2020,
	title = {The {Rigor} and {Transparency} {Index} {Quality} {Metric} for {Assessing} {Biological} and {Medical} {Science} {Methods}},
	volume = {23},
	issn = {2589-0042},
	doi = {10.1016/j.isci.2020.101698},
	language = {English},
	number = {11},
	journal = {iScience},
	author = {Menke, Joe and Roelandse, Martijn and Ozyurt, Burak and Martone, Maryann and Bandrowski, Anita},
	month = nov,
	year = {2020},
	pmid = {33196023},
	publisher = {Elsevier},
	keywords = {Bioinformatics, Biological Sciences, Biological Sciences Research Methodologies, Methodology in Biological Sciences}
}

@article{tibav:42484,
  title={Keynote at {deRSE} 2019: {Delivering} on the promise of {Research Computing}},
  author={Bouffler, Brendan},
  journal={{TIB AV-PORTAL}},
  howpublished={Gesellschaft für Informatik e.V. \(GI\)},
  year={2019},
  doi = {10.5446/42484},
  note={Video recording published in {TIB AV-PORTAL}},
}

% via https://twitter.com/tsuyomiyakawa/status/1230672758163402752?s=09
@article{miyakawa_no_2020,
	title = {No raw data, no science: another possible source of the reproducibility crisis},
	volume = {13},
	issn = {1756-6606},
	doi = {10.1186/s13041-020-0552-2},
	abstract = {A reproducibility crisis is a situation where many scientific studies cannot be reproduced. Inappropriate practices of science, such as HARKing, p-hacking, and selective reporting of positive results, have been suggested as causes of irreproducibility. In this editorial, I propose that a lack of raw data or data fabrication is another possible cause of irreproducibility.},
	number = {1},
	urldate = {2021-01-12},
	journal = {Molecular Brain},
	author = {Miyakawa, Tsuyoshi},
	month = feb,
	year = {2020},
	keywords = {Data fabrication, Misconduct, Open data, Open science, Raw data, Reproducibility},
	pages = {24}
}

@article{nosek_scientific_2012,
	title = {Scientific {Utopia} {II}. {Restructuring} {Incentives} and {Practices} to {Promote} {Truth} {Over} {Publishability}},
	volume = {7},
	issn = {1745-6916, 1745-6924},
	doi = {10.1177/1745691612459058},
	abstract = {An academic scientist’s professional success depends on publishing. Publishing norms emphasize novel, positive results. As such, disciplinary incentives encourage design, analysis, and reporting decisions that elicit positive results and ignore negative results. Prior reports demonstrate how these incentives inflate the rate of false effects in published science. When incentives favor novelty over replication, false results persist in the literature unchallenged, reducing efficiency in knowledge accumulation. Previous suggestions to address this problem are unlikely to be effective. For example, a journal of negative results publishes otherwise unpublishable reports. This enshrines the low status of the journal and its content. The persistence of false findings can be meliorated with strategies that make the fundamental but abstract accuracy motive—getting it right—competitive with the more tangible and concrete incentive—getting it published. This article develops strategies for improving scientific practices and knowledge accumulation that account for ordinary human motivations and biases.},
	language = {en},
	number = {6},
	urldate = {2016-03-10},
	journal = {Perspectives on Psychological Science},
	author = {Nosek, Brian A. and Spies, Jeffrey R. and Motyl, Matt},
	month = nov,
	year = {2012},
	pmid = {26168121},
	keywords = {false positives, incentives, methodology, motivated reasoning, replication},
	pages = {615--631}
}

@article{mcdougal_reproducibility_2016,
	title = {Reproducibility in {Computational} {Neuroscience} {Models} and {Simulations}},
	volume = {63},
	issn = {0018-9294},
	doi = {10.1109/TBME.2016.2539602},
	abstract = {Objective
Like all scientific research, computational neuroscience research
must be reproducible. Big data science, including simulation research,
cannot depend exclusively on journal articles as the method to provide the
sharing and transparency required for reproducibility.

Methods
Ensuring model reproducibility requires the use of multiple standard
software practices and tools, including version control, strong commenting
and documentation, and code modularity.

Results
Building on these standard practices, model sharing sites and tools
have been developed that fit into several categories: 1. standardized neural
simulators, 2. shared computational resources, 3. declarative model
descriptors, ontologies and standardized annotations; 4. model sharing
repositories and sharing standards.

Conclusion
A number of complementary innovations have been proposed to enhance
sharing, transparency and reproducibility. The individual user can be
encouraged to make use of version control, commenting, documentation and
modularity in development of models. The community can help by requiring
model sharing as a condition of publication and funding.

Significance
Model management will become increasingly important as multiscale
models become larger, more detailed and correspondingly more difficult to
manage by any single investigator or single laboratory. Additional
big data management complexity will come as the models
become more useful in interpreting experiments, thus increasing the need to
ensure clear alignment between modeling data, both parameters and results,
and experiment.},
	number = {10},
	journal = {IEEE transactions on bio-medical engineering},
	author = {McDougal, Robert A. and Bulanova, Anna S. and Lytton, William W.},
	month = oct,
	year = {2016},
	pmid = {27046845},
	pmcid = {PMC5016202},
	pages = {2021--2035}
}

@article{barba_praxis_2018,
	title = {Praxis of {Reproducible} {Computational} {Science}},
	doi = {10.22541/au.153922477.77361922},
	abstract = {Among the top challenges of reproducible computational science are: (1) creation, curation, usage and publication of research software; (2) acceptance, adoption and standardization of open-science practices; (3) misalignment with academic incentive structures and institutional processes for career progression. I will address here mainly the first two, proposing a praxis of reproducible computational science.},
	language = {en},
	urldate = {2021-02-02},
	author = {Barba, Lorena A},
	month = oct,
	year = {2018}
}
