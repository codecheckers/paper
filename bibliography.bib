
@ARTICLE{Gronenschild2012-pp,
  title    = "The effects of {FreeSurfer} version, workstation type, and
              Macintosh operating system version on anatomical volume and
              cortical thickness measurements",
  author   = "Gronenschild, Ed H B M and Habets, Petra and Jacobs, Heidi I L
              and Mengelers, Ron and Rozendaal, Nico and van Os, Jim and
              Marcelis, Machteld",
  abstract = "FreeSurfer is a popular software package to measure cortical
              thickness and volume of neuroanatomical structures. However,
              little if any is known about measurement reliability across
              various data processing conditions. Using a set of 30 anatomical
              T1-weighted 3T MRI scans, we investigated the effects of data
              processing variables such as FreeSurfer version (v4.3.1, v4.5.0,
              and v5.0.0), workstation (Macintosh and Hewlett-Packard), and
              Macintosh operating system version (OSX 10.5 and OSX 10.6).
              Significant differences were revealed between FreeSurfer version
              v5.0.0 and the two earlier versions. These differences were on
              average 8.8 $\pm$ 6.6\% (range 1.3-64.0\%) (volume) and 2.8 $\pm$
              1.3\% (1.1-7.7\%) (cortical thickness). About a factor two
              smaller differences were detected between Macintosh and
              Hewlett-Packard workstations and between OSX 10.5 and OSX 10.6.
              The observed differences are similar in magnitude as effect sizes
              reported in accuracy evaluations and neurodegenerative
              studies.The main conclusion is that in the context of an ongoing
              study, users are discouraged to update to a new major release of
              either FreeSurfer or operating system or to switch to a different
              type of workstation without repeating the analysis; results thus
              give a quantitative support to successive recommendations stated
              by FreeSurfer developers over the years. Moreover, in view of the
              large and significant cross-version differences, it is concluded
              that formal assessment of the accuracy of FreeSurfer is
              desirable.",
  journal  = "PLoS One",
  volume   =  7,
  number   =  6,
  pages    = "e38234",
  month    =  jun,
  year     =  2012,
  language = "en",
  issn     = "1932-6203",
  pmid     = "22675527",
  doi      = "10.1371/journal.pone.0038234",
  pmc      = "PMC3365894"
}

@article{cert-2020-001,
  author =	 {Stephen J. Eglen},
  title =	 {CODECHECK Certificate 2020-001},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Piccolo2020-lo,
  title    = "{ShinyLearner}: A containerized benchmarking tool for
              machine-learning classification of tabular data",
  author   = "Piccolo, Stephen R and Lee, Terry J and Suh, Erica and Hill,
              Kimball",
  journal  = "Gigascience",
  volume   =  9,
  number   =  4,
  month    =  apr,
  year     =  2020,
  keywords = "algorithm optimization; benchmark; classification; feature
              selection; machine learning; model selection; software
              containers; supervised learning",
  language = "en",
  issn     = "2047-217X",
  pmid     = "32249316",
  doi      = "10.1093/gigascience/giaa026",
  pmc      = "PMC7131989"
}

@article{cert-2020-002,
  author =	 {Stephen J. Eglen and Daniel N\"{u}st},
  title =	 {CODECHECK Certificate 2020-002},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Hancock1992-mp,
  title     = "The principal components of natural images",
  author    = "Hancock, Peter J B and Baddeley, Roland J and Smith, Leslie S",
  abstract  = "A neural net was used to analyse samples of natural images and
               text. For the natural images, components resemble derivatives of
               Gaussian operators, similar to those found in visual cortex and
               inferred from psychophysics. While the results from natural
               images do not depend on scale, those from text images are highly
               scale dependent. Convolution of one of the text components with
               an original image shows that it is sensitive to inter-word gaps.",
  journal   = "Network: Computation in Neural Systems",
  publisher = "Taylor \& Francis",
  volume    =  3,
  number    =  1,
  pages     = "61--70",
  year      =  1992,
  eprint    = "http://www.tandfonline.com/doi/pdf/10.1088/0954-898X\_3\_1\_008",
  doi       = "10.1088/0954-898X_3_1_008"
}

@article{cert-2020-003,
  author =	 {Daniel N\"{u}st},
  title =	 {CODECHECK Certificate 2020-003},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Hopfield1982-mz,
  title    = "Neural networks and physical systems with emergent collective
              computational abilities",
  author   = "Hopfield, J J",
  abstract = "Computational properties of use of biological organisms or to the
              construction of computers can emerge as collective properties of
              systems having a large number of simple equivalent components (or
              neurons). The physical meaning of content-addressable memory is
              described by an appropriate phase space flow of the state of a
              system. A model of such a system is given, based on aspects of
              neurobiology but readily adapted to integrated circuits. The
              collective properties of this model produce a content-addressable
              memory which correctly yields an entire memory from any subpart
              of sufficient size. The algorithm for the time evolution of the
              state of the system is based on asynchronous parallel processing.
              Additional emergent collective properties include some capacity
              for generalization, familiarity recognition, categorization,
              error correction, and time sequence retention. The collective
              properties are only weakly sensitive to details of the modeling
              or the failure of individual devices.",
  journal  = "Proc. Natl. Acad. Sci. U. S. A.",
  volume   =  79,
  number   =  8,
  pages    = "2554--2558",
  month    =  apr,
  year     =  1982,
  language = "en",
  issn     = "0027-8424",
  pmid     = "6953413",
  doi      = "10.1073/pnas.79.8.2554",
  pmc      = "PMC346238"
}

@article{cert-2020-004,
  author =	 {Daniel N\"{u}st},
  title =	 {CODECHECK Certificate 2020-004},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Barto1983-rg,
  title    = "Neuronlike adaptive elements that can solve difficult learning
              control problems",
  author   = "Barto, A G and Sutton, R S and Anderson, C W",
  abstract = "It is shown how a system consisting of two neuronlike adaptive
              elements can solve a difficult learning control problem. The task
              is to balance a pole that is hinged to a movable cart by applying
              forces to the cart's base. It is argued that the learning
              problems faced by adaptive elements that are components of
              adaptive networks are at least as difficult as this version of
              the pole-balancing problem. The learning system consists of a
              single associative search element (ASE) and a single adaptive
              critic element (ACE). In the course of learning to balance the
              pole, the ASE constructs associations between input and output by
              searching under the influence of reinforcement feedback, and the
              ACE constructs a more informative evaluation function than
              reinforcement feedback alone can provide. The differences between
              this approach and other attempts to solve problems using
              neurolike elements are discussed, as is the relation of this work
              to classical and instrumental conditioning in animal learning
              studies and its possible implications for research in the
              neurosciences.",
  journal  = "IEEE Trans. Syst. Man Cybern.",
  volume   = "SMC-13",
  number   =  5,
  pages    = "834--846",
  month    =  sep,
  year     =  1983,
  keywords = "adaptive control;learning systems;neural nets;neural
              nets;adaptive control;neuronlike adaptive elements;learning
              control problem;movable cart;associative search element;adaptive
              critic element;animal learning studies;Adaptive
              systems;Problem-solving;Training;Pattern
              recognition;Neurons;Supervised learning;Biological neural
              networks",
  issn     = "0018-9472, 2168-2909",
  doi      = "10.1109/TSMC.1983.6313077"
}

@article{cert-2020-005,
  author =	 {Stephen J. Eglen},
  title =	 {CODECHECK Certificate 2020-005},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{cert-2020-006,
  author =	 {Stephen J. Eglen},
  title =	 {CODECHECK Certificate 2020-006},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{cert-2020-007,
  author =	 {Stephen J. Eglen},
  title =	 {CODECHECK Certificate 2020-007},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{cert-2020-008,
  author =	 {Stephen J. Eglen},
  title =	 {CODECHECK Certificate 2020-008},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Davies2020-vj,
  title     = "Effects of non-pharmaceutical interventions on {COVID-19} cases,
               deaths, and demand for hospital services in the {UK}: a
               modelling study",
  author    = "Davies, Nicholas G and Kucharski, Adam J and Eggo, Rosalind M
               and Gimma, Amy and Edmunds, W John and Jombart, Thibaut and
               O'Reilly, Kathleen and Endo, Akira and Hellewell, Joel and
               Nightingale, Emily S and Quilty, Billy J and Jarvis, Christopher
               I and Russell, Timothy W and Klepac, Petra and Bosse, Nikos I
               and Funk, Sebastian and Abbott, Sam and Medley, Graham F and
               Gibbs, Hamish and Pearson, Carl A B and Flasche, Stefan and Jit,
               Mark and Clifford, Samuel and Prem, Kiesha and Diamond, Charlie
               and Emery, Jon and Deol, Arminder K and Procter, Simon R and van
               Zandvoort, Kevin and Sun, Yueqian Fiona and Munday, James D and
               Rosello, Alicia and Auzenbergs, Megan and Knight, Gwen and
               Houben, Rein M G J and Liu, Yang",
  abstract  = "BackgroundNon-pharmaceutical interventions have been implemented
               to reduce transmission of severe acute respiratory syndrome
               coronavirus 2 (SARS-CoV-2) in the UK. Projecting the size of an
               unmitigated epidemic and the potential effect of different
               control measures has been crucial to support evidence-based
               policy making during the early stages of the epidemic. This
               study assesses the potential impact of different control
               measures for mitigating the burden of COVID-19 in the UK.",
  journal   = "The Lancet Public Health",
  publisher = "Elsevier",
  month     =  jun,
  year      =  2020,
  issn      = "2468-2667",
  doi       = "10.1016/S2468-2667(20)30133-X"
}

@article{cert-2020-009,
  author =	 {Stephen J. Eglen},
  title =	 {CODECHECK Certificate 2020-009},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{cert-2020-010,
  author =	 {Stephen J. Eglen},
  title =	 {CODECHECK Certificate 2020-001},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{cert-2020-011,
  author =	 {Stephen J. Eglen},
  title =	 {CODECHECK Certificate 2020-001},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@ARTICLE{Flaxman2020-yb,
  title    = "Estimating the effects of non-pharmaceutical interventions on
              {COVID-19} in Europe",
  author   = "Flaxman, Seth and Mishra, Swapnil and Gandy, Axel and Unwin, H
              Juliette T and Mellan, Thomas A and Coupland, Helen and
              Whittaker, Charles and Zhu, Harrison and Berah, Tresnia and
              Eaton, Jeffrey W and Monod, M{\'e}lodie and {Imperial College
              COVID-19 Response Team} and Ghani, Azra C and Donnelly, Christl A
              and Riley, Steven M and Vollmer, Michaela A C and Ferguson, Neil
              M and Okell, Lucy C and Bhatt, Samir",
  abstract = "Following the emergence of a novel coronavirus1 (SARS-CoV-2) and
              its spread outside of China, Europe has experienced large
              epidemics. In response, many European countries have implemented
              unprecedented non-pharmaceutical interventions such as closure of
              schools and national lockdowns. We study the impact of major
              interventions across 11 European countries for the period from
              the start of COVID-19 until the 4th of May 2020 when lockdowns
              started to be lifted. Our model calculates backwards from
              observed deaths to estimate transmission that occurred several
              weeks prior, allowing for the time lag between infection and
              death. We use partial pooling of information between countries
              with both individual and shared effects on the reproduction
              number. Pooling allows more information to be used, helps
              overcome data idiosyncrasies, and enables more timely estimates.
              Our model relies on fixed estimates of some epidemiological
              parameters such as the infection fatality rate, does not include
              importation or subnational variation and assumes that changes in
              the reproduction number are an immediate response to
              interventions rather than gradual changes in behavior. Amidst the
              ongoing pandemic, we rely on death data that is incomplete, with
              systematic biases in reporting, and subject to future
              consolidation. We estimate that, for all the countries we
              consider, current interventions have been sufficient to drive the
              reproduction number [Formula: see text] below 1 (probability
              [Formula: see text]< 1.0 is 99.9\%) and achieve epidemic control.
              We estimate that, across all 11 countries, between 12 and 15
              million individuals have been infected with SARS-CoV-2 up to 4th
              May, representing between 3.2\% and 4.0\% of the population. Our
              results show that major non-pharmaceutical interventions and
              lockdown in particular have had a large effect on reducing
              transmission. Continued intervention should be considered to keep
              transmission of SARS-CoV-2 under control.",
  journal  = "Nature",
  month    =  jun,
  year     =  2020,
  language = "en",
  issn     = "0028-0836, 1476-4687",
  pmid     = "32512579",
  doi      = "10.1038/s41586-020-2405-7"
}

@article{cert-2020-012,
  author =	 {Stephen J. Eglen},
  title =	 {CODECHECK Certificate 2020-012},
  year =	 2020,
  doi =		 "10.5281/zenodo.3893617",
  journal =	 {Zenodo}
}

@article{Unwin2020,
  title  = "Report 23: State-level tracking of {COVID-19} in the United States",
  author = "Unwin, H and Mishra, Swapnil and Bradley, Valerie C and Gandy, A
            and Vollmer, M and Mellan, T and Coupland, H and Ainslie, K and
            Whittaker, C and Ish-Horowicz, J and {Others}",
  doi    = "10.25561/79231"
}

@article{cert-2020-013,
  author       = {Iain Davies},
  title        = {CODECHECK certificate 2020-013},
  month        = jul,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3947959}
}

@article{Spitschan2020.06.02.129502,
	title = {Rest-activity cycles and melatonin phase angle of circadian entrainment in people without cone-mediated vision},
	doi = {10.1101/2020.06.02.129502},
	journal = {bioRxiv},
	author = {Spitschan, Manuel and Garbazza, Corrado and Kohl, Susanne and Cajochen, Christian},
	year = {2020},
	publisher = {Cold Spring Harbor Laboratory}
}

@article{cert-2020-014,
  author       = {Iain Davies},
  title        = {CODECHECK certificate 2020-014},
  month        = jul,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3967326}
}

@article{Sadeh2020,
  doi = {10.7554/elife.52757},
  year = {2020},
  month = feb,
  publisher = {{eLife} Sciences Publications,  Ltd},
  volume = {9},
  author = {Sadra Sadeh and Claudia Clopath},
  title = {Patterned perturbation of inhibition can reveal the dynamical structure of neural processing},
  journal = {{eLife}}
}

@article{cert-2020-015,
  author       = {Iain Davies},
  title        = {CODECHECK certificate 2020-015},
  month        = aug,
  year         = 2020,
  note         = {{See file LICENSE for license of the contained 
                   code. The report document codecheck.pdf is
                   published under CC-BY 4.0 International.}},
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3978402},
}

@article{Liou2020,
  doi = {10.7554/elife.50927},
  year = {2020},
  month = mar,
  publisher = {{eLife} Sciences Publications,  Ltd},
  volume = {9},
  author = {Jyun-you Liou and Elliot H Smith and Lisa M Bateman and Samuel L Bruce and Guy M McKhann and Robert R Goodman and Ronald G Emerson and Catherine A Schevon and LF Abbott},
  title = {A model for focal seizure onset,  propagation,  evolution,  and progression},
  journal = {{eLife}}
}

@article{cert-2020-016,
  author       = {Daniel N\"ust},
  title        = {CODECHECK certificate 2020-016},
  month        = jun,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.3981253}
}

@article{Brunsdon2020,
  doi = {10.1007/s10109-020-00334-2},
  year = {2020},
  month = aug,
  publisher = {Springer Science and Business Media {LLC}},
  author = {Chris Brunsdon and Alexis Comber},
  title = {Opening practice: supporting reproducibility and critical spatial data science},
  journal = {Journal of Geographical Systems}
}

@article{cert-2020-017,
  author       = {Daniel N\"ust},
  title        = {CODECHECK certificate 2020-017},
  month        = aug,
  year         = 2020,
  publisher    = {Zenodo},
  doi          = {10.5281/zenodo.4003848}
}

@article{Bivand2020,
  doi = {10.1007/s10109-020-00336-0},
  year = {2020},
  publisher = {Springer Science and Business Media {LLC}},
  author = {Bivand, Roger S.},
  title = {Progress in the R ecosystem for representing and handling spatialdata},
  journal = {Journal of Geographical Systems}
}

@article{cert-2020-018,
  doi = {10.17605/OSF.IO/ZTC7M},
  author = {N\"{u}st,  Daniel},
  title = {Reproducibility review of: Integrating cellular automata and discrete global grid systems: a case study into wildfire modelling},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Hojati2020,
  doi = {10.5194/agile-giss-1-6-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--23},
  author = {Majid Hojati and Colin Robertson},
  title = {Integrating cellular automata and discrete global grid systems: a case study into wildfire modelling},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-019,
  doi = {10.17605/OSF.IO/5SVMT},
  author = {N\"{u}st,  Daniel and Granell,  Carlos},
  title = {Reproducibility review of: What to do in the Meantime: A Service Coverage Analysis for Parked Autonomous Vehicles},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Illium2020,
  doi = {10.5194/agile-giss-1-7-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--15},
  author = {Steffen Illium and Philipp Andreas Friese and Robert M\"{u}ller and Sebastian Feld},
  title = {What to do in the Meantime: A Service Coverage Analysis for Parked Autonomous Vehicles},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-020,
  doi = {10.17605/OSF.IO/7TWR2},
  author = {N\"{u}st,  Daniel and Ostermann,  Frank},
  title = {Reproducibility review of: Window Operators for Processing Spatio-Temporal Data Streams on Unmanned Vehicles},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Werner2020,
  doi = {10.5194/agile-giss-1-21-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--23},
  author = {Tobias Werner and Thomas Brinkhoff},
  title = {Window Operators for Processing Spatio-Temporal Data Streams on Unmanned Vehicles},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-021,
  doi = {10.17605/OSF.IO/SUWPJ},
  author = {Ostermann,  Frank and N\"{u}st,  Daniel},
  title = {Reproducibility Review of: Comparing supervised learning algorithms for Spatial Nominal Entity recognition},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Medad2020,
  doi = {10.5194/agile-giss-1-15-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--18},
  author = {Amine Medad and Mauro Gaio and Ludovic Moncla and S{\'{e}}bastien Musti{\`{e}}re and Yannick Le Nir},
  title = {Comparing supervised learning algorithms for Spatial Nominal Entity recognition},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-022,
  doi = {10.17605/OSF.IO/7XRQG},
  author = {N\"{u}st,  Daniel},
  title = {Reproducibility review of: Extracting interrogative intents and concepts from geo-analytic questions},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Xu2020,
  doi = {10.5194/agile-giss-1-23-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--21},
  author = {Haiqi Xu and Ehsan Hamzei and Enkhbold Nyamsuren and Han Kruiger and Stephan Winter and Martin Tomko and Simon Scheider},
  title = {Extracting interrogative intents and concepts from geo-analytic questions},
  journal = {{AGILE}: {GIScience} Series}
}

@article{cert-2020-023,
  doi = {10.17605/OSF.IO/XS5YR},
  author = {Ostermann,  Frank and N\"{u}st,  Daniel},
  title = {Reproducibility review of: Tracking Hurricane Dorian in GDELT and Twitter},
  publisher = {Open Science Framework},
  year = {2020}
}

@article{Owuor2020,
  doi = {10.5194/agile-giss-1-19-2020},
  year = {2020},
  month = jul,
  publisher = {Copernicus {GmbH}},
  volume = {1},
  pages = {1--18},
  author = {Innocensia Owuor and Hartwig H. Hochmair and Sreten Cvetojevic},
  title = {Tracking Hurricane Dorian in {GDELT} and Twitter},
  journal = {{AGILE}: {GIScience} Series}
}

@ARTICLE{Barnes2010-iv,
  title   = "Publish your computer code: it is good enough",
  author  = "Barnes, Nick",
  journal = "Nature",
  volume  =  467,
  number  =  7317,
  pages   = "753",
  month   =  oct,
  year    =  2010,
  issn    = "0028-0836, 1476-4687",
  pmid    = "20944687",
  doi     = "10.1038/467753a"
}

@article{sandve_ten_2013,
	title = {Ten {Simple} {Rules} for {Reproducible} {Computational} {Research}},
	volume = {9},
	doi = {10.1371/journal.pcbi.1003285},
	number = {10},
	journal = {PLoS Comput Biol},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	year = {2013},
	keywords = {Archives, Computer and information sciences, Computer applications, Habits, Replication studies, Reproducibility, Sequence analysis, Source code},
	pages = {e1003285}
}

@article{rule_ten_2019,
	title = {Ten simple rules for writing and sharing computational analyses in {Jupyter} {Notebooks}},
	volume = {15},
	issn = {1553-7358},
	doi = {10.1371/journal.pcbi.1007007},
	language = {en},
	number = {7},
	journal = {PLOS Computational Biology},
	author = {Rule, Adam and Birmingham, Amanda and Zuniga, Cristal and Altintas, Ilkay and Huang, Shih-Cheng and Knight, Rob and Moshiri, Niema and Nguyen, Mai H. and Rosenthal, Sara Brin and Pérez, Fernando and Rose, Peter W.},
	year = {2019},
	keywords = {Reproducibility, Data processing, Computer and information sciences, Metadata, Analysts, Computer hardware, Ecosystems, Graphical user interfaces},
	pages = {e1007007}
}

@article{peng_reproducible_2011,
	title = {Reproducible {Research} in {Computational} {Science}},
	volume = {334},
	copyright = {Copyright © 2011, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.1213847},
	abstract = {Computational science has led to exciting new developments, but the nature of the work has exposed limitations in our ability to evaluate published findings. Reproducibility has the potential to serve as a minimum standard for judging scientific claims when full independent replication of a study is not possible.},
	language = {en},
	number = {6060},
	journal = {Science},
	author = {Peng, Roger D.},
	year = {2011},
	pmid = {22144613},
	pages = {1226--1227}
}

@article{barba_terminologies_2018,
	title = {Terminologies for {Reproducible} {Research}},
	url = {http://arxiv.org/abs/1802.03311},
	abstract = {Reproducible research---by its many names---has come to be regarded as a key concern across disciplines and stakeholder groups. Funding agencies and journals, professional societies and even mass media are paying attention, often focusing on the so-called "crisis" of reproducibility. One big problem keeps coming up among those seeking to tackle the issue: different groups are using terminologies in utter contradiction with each other. Looking at a broad sample of publications in different fields, we can classify their terminology via decision tree: they either, A---make no distinction between the words reproduce and replicate, or B---use them distinctly. If B, then they are commonly divided in two camps. In a spectrum of concerns that starts at a minimum standard of "same data+same methods=same results," to "new data and/or new methods in an independent study=same findings," group 1 calls the minimum standard reproduce, while group 2 calls it replicate. This direct swap of the two terms aggravates an already weighty issue. By attempting to inventory the terminologies across disciplines, I hope that some patterns will emerge to help us resolve the contradictions.},
	journal = {arXiv:1802.03311 [cs]},
	author = {Barba, Lorena A.},
	year = {2018},
	keywords = {Computer Science - Digital Libraries}
}

@article{chen_open_2019,
	title = {Open is not enough},
	volume = {15},
	copyright = {2018 Springer Nature Limited},
	issn = {1745-2481},
	doi = {10.1038/s41567-018-0342-2},
	abstract = {The solutions adopted by the high-energy physics community to foster reproducible research are examples of best practices that could be embraced more widely. This first experience suggests that reproducibility requires going beyond openness.},
	language = {En},
	number = {2},
	journal = {Nature Physics},
	author = {Chen, Xiaoli and Dallmeier-Tiessen, S{\"u}nje and Dasler, Robin and Feger, Sebastian and Fokianos, Pamfilos and Gonzalez, Jose Benito and Hirvonsalo, Harri and Kousidis, Dinos and Lavasa, Artemis and Mele, Salvatore and Rodríguez, Diego and \v{S}imko, Tibor and Smith, Tim and Trisovic, Ana and Trzcinska, Anna and Tsanaktsidis, Ioannis and Zimmermann, Markus and Cranmer, Kyle and Heinrich, Lukas and Watts, Gordon and Hildreth, Michael and Iglesias, Lara Lloret and Lassila-Perini, Kati and Neubert, Sebastian},
	year = {2019},
	pages = {113}
}

@article{schonbrodt_training_2019,
	title = {Training students for the {Open} {Science} future},
	volume = {3},
	issn = {2397-3374},
	doi = {10.1038/s41562-019-0726-z},
	language = {en},
	number = {10},
	journal = {Nature Human Behaviour},
	author = {Sch{\"o}nbrodt, Felix},
	year = {2019},
	pages = {1031--1031}
}

@article{piwowar_altmetrics:_2013,
	title = {Altmetrics: {Value} all research products},
	volume = {493},
	copyright = {2013 Nature Publishing Group},
	issn = {1476-4687},
	shorttitle = {Altmetrics},
	doi = {10.1038/493159a},
	abstract = {A new funding policy by the US National Science Foundation represents a sea-change in how researchers are evaluated, says Heather Piwowar.},
	language = {en},
	journal = {Nature},
	author = {Piwowar, Heather},
	year = {2013},
	pages = {159}
}

@article{donoho_invitation_2010,
	title = {An invitation to reproducible computational research},
	volume = {11},
	issn = {1465-4644},
	doi = {10.1093/biostatistics/kxq028},
	abstract = {I am genuinely thrilled to see Biostatistics make a formal venture into computational reproducibility, and I congratulate the editors of Biostatistics on taking},
	language = {en},
	number = {3},
	journal = {Biostatistics},
	author = {Donoho, David L.},
	year = {2010},
	pages = {385--388}
}

@incollection{claerbout_electronic_1992,
	series = {{SEG} {Technical} {Program} {Expanded} {Abstracts}},
	title = {Electronic documents give reproducible research a new meaning},
	doi = {10.1190/1.1822162},
	booktitle = {{SEG} {Technical} {Program} {Expanded} {Abstracts} 1992},
	publisher = {Society of Exploration Geophysicists},
	author = {Claerbout, J. and Karrenbach, M.},
	year = {1992},
	pages = {601--604}
}

@article{markowetz_five_2015,
	title = {Five selfish reasons to work reproducibly},
	volume = {16},
	issn = {1474-760X},
	doi = {10.1186/s13059-015-0850-7},
	abstract = {And so, my fellow scientists: ask not what you can do for reproducibility; ask what reproducibility can do for you! Here, I present five reasons why working reproducibly pays off in the long run and is in the self-interest of every ambitious, career-oriented scientist.},
	journal = {Genome Biology},
	author = {Markowetz, Florian},
	year = {2015},
	keywords = {Reproducibility, Scientific career},
	pages = {274}
}

@article{gentleman_statistical_2007,
	title = {Statistical {Analyses} and {Reproducible} {Research}},
	volume = {16},
	issn = {1061-8600},
	doi = {10.1198/106186007X178663},
	abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents---including figures, tables, and so on---can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection.The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
	number = {1},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Gentleman, Robert and Lang, Duncan Temple},
	year = {2007},
	pages = {1--23}
}

@article{boettiger_introduction_2015,
	title = {An {Introduction} to {Docker} for {Reproducible} {Research}},
	volume = {49},
	issn = {0163-5980},
	doi = {10.1145/2723872.2723882},
	abstract = {As computational work becomes more and more integral to many aspects of scientific research, computational reproducibility has become an issue of increasing importance to computer systems researchers and domain scientists alike. Though computational reproducibility seems more straight forward than replicating physical experiments, the complex and rapidly changing nature of computer environments makes being able to reproduce and extend such work a serious challenge. In this paper, I explore common reasons that code developed for one research project cannot be successfully executed or extended by subsequent researchers. I review current approaches to these issues, including virtual machines and workflow systems, and their limitations. I then examine how the popular emerging technology Docker combines several areas from systems research - such as operating system virtualization, cross-platform portability, modular re-usable elements, versioning, and a 'DevOps' philosophy, to address these challenges. I illustrate this with several examples of Docker use with a focus on the R statistical environment.},
	number = {1},
	journal = {SIGOPS Oper. Syst. Rev.},
	author = {Boettiger, Carl},
	year = {2015},
	keywords = {Computer Science - Software Engineering},
	pages = {71--79}
}

@article{howe_virtual_2012,
	title = {Virtual {Appliances}, {Cloud} {Computing}, and {Reproducible} {Research}},
	volume = {14},
	issn = {1521-9615},
	doi = {10.1109/MCSE.2012.62},
	abstract = {As science becomes increasingly computational, reproducibility has become increasingly difficult, perhaps surprisingly. In many contexts, virtualization and cloud computing can mitigate the issues involved without significant overhead to the researcher, enabling the next generation of rigorous and reproducible computational science.},
	number = {4},
	journal = {Computing in Science Engineering},
	author = {Howe, B.},

	year = {2012},
	keywords = {case studies in scientific applications, Cloud computing, context awareness, Documentation, Information Retrieval, Information Storage and Retrieval, Reproducibility of results, reproducible results, research and development, Scientific computing, services computing, Virtual machining},
	pages = {36--41}
}

@article{kurtzer_singularity:_2017,
	title = {Singularity: {Scientific} containers for mobility of compute},
	volume = {12},
	issn = {1932-6203},
	shorttitle = {Singularity},
	url = {https://10.1371/journal.pone.0177459},
	doi = {10.1371/journal.pone.0177459},
	abstract = {Here we present Singularity, software developed to bring containers and reproducibility to scientific computing. Using Singularity containers, developers can work in reproducible environments of their choosing and design, and these complete environments can easily be copied and executed on other platforms. Singularity is an open source initiative that harnesses the expertise of system and software engineers and researchers alike, and integrates seamlessly into common workflows for both of these groups. As its primary use case, Singularity brings mobility of computing to both users and HPC centers, providing a secure means to capture and distribute software and compute environments. This ability to create and deploy reproducible environments across these centers, a previously unmet need, makes Singularity a game changing development for computational science.},
	number = {5},
	journal = {PLOS ONE},
	author = {Kurtzer, Gregory M. and Sochat, Vanessa and Bauer, Michael W.},
	year = {2017},
	keywords = {Computer software, Operating Systems, software development, Open source software, Software tools, Research validity, Tar, Software design},
	pages = {e0177459}
}

@article{knuth_literate_1984,
	title = {Literate {Programming}},
	volume = {27},
	issn = {0010-4620},
	doi = {10.1093/comjnl/27.2.97},
	number = {2},
	journal = {Comput. J.},
	author = {Knuth, Donald E.},
	year = {1984},
	pages = {97--111}
}

@misc{marwick_how_2015,
	title = {How computers broke science – and what we can do to fix it},
	copyright = {Copyright © 2010–2019, The Conversation Trust (UK) Limited},
	url = {http://theconversation.com/how-computers-broke-science-and-what-we-can-do-to-fix-it-49938},
	abstract = {Virtually every researcher relies on computers to collect or analyze data. But when computers are opaque black boxes that manipulate data, it's impossible to replicate studies – a core value for science.},
	language = {en},
	urldate = {2017-07-05},
	journal = {The Conversation},
	author = {Marwick, Ben},
	year = {2015}
}

@article{eglen_recent_2018,
	title = {Recent developments in scholarly publishing to improve research practices in the life sciences},
	volume = {2},
	copyright = {© 2018 The Author(s). https://creativecommons.org/licenses/by-nc-nd/4.0/This is an open access article published by Portland Press Limited on behalf of the Biochemical Society and the Royal Society of Biology and distributed under the Creative Commons Attribution License 4.0 (CC BY-NC-ND).},
	issn = {2397-8554, 2397-8562},
	doi = {10.1042/ETLS20180172},
	abstract = {We outline recent developments in scholarly publishing that we think will improve the working environment and career prospects for life scientists. Most prominently, we discuss two key developments. (1) Life scientists are now embracing a preprint culture leading to rapid dissemination of research findings. (2) We outline steps to overcome the reproducibility crisis. We also briefly describe other innovations in scholarly publishing, along with changes to open access mandates from funding agencies.},
	language = {en},
	number = {6},
	journal = {Emerging Topics in Life Sciences},
	author = {Eglen, Stephen J. and Mounce, Ross and Gatto, Laurent and Currie, Adrian M. and Nobis, Yvonne},
	year = {2018},
	pages = {775--778}
}

@article{fanelli_opinion:_2018,
	title = {Opinion: {Is} science really facing a reproducibility crisis, and do we need it to?},
	copyright = {© 2018 . Published under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	shorttitle = {Opinion},
	doi = {10.1073/pnas.1708272114},
	abstract = {Efforts to improve the reproducibility and integrity of science are typically justified by a narrative of crisis, according to which most published results are unreliable due to growing problems with research and publication practices. This article provides an overview of recent evidence suggesting that this narrative is mistaken, and argues that a narrative of epochal changes and empowerment of scientists would be more accurate, inspiring, and compelling.},
	language = {en},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Fanelli, Daniele},
	year = {2018},
	pmid = {29531051},
	keywords = {reproducible research, bias, crisis, integrity, misconduct},
	pages = {201708272}
}

@article{eglen_toward_2017,
	title = {Toward standard practices for sharing computer code and programs in neuroscience},
	volume = {20},
	copyright = {2017 Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
	issn = {1546-1726},
	doi = {10.1038/nn.4550},
	abstract = {Computational techniques are central in many areas of neuroscience and are relatively easy to share. This paper describes why computer programs underlying scientific publications should be shared and lists simple steps for sharing. Together with ongoing efforts in data sharing, this should aid reproducibility of research.},
	language = {en},
	number = {6},
	journal = {Nature Neuroscience},
	author = {Eglen, Stephen J. and Marwick, Ben and Halchenko, Yaroslav O. and Hanke, Michael and Sufi, Shoaib and Gleeson, Padraig and Silver, R. Angus and Davison, Andrew P. and Lanyon, Linda and Abrams, Mathew and Wachtler, Thomas and Willshaw, David J. and Pouzat, Christophe and Poline, Jean-Baptiste},
	year = {2017},
	pages = {770--773}
}

@article{kluyver_jupyter_2016,
	title = {Jupyter {Notebooks} - a publishing format for reproducible computational workflows},
	doi = {10.3233/978-1-61499-649-1-87},
	abstract = {It is increasingly necessary for researchers in all fields to write computer code, and in order to reproduce research results, it is important that this code is published. We present Jupyter notebooks, a document format for publishing code, results and explanations in a form that is both readable and executable. We discuss various tools and use cases for notebook documents.},
	journal = {Positioning and Power in Academic Publishing: Players, Agents and Agendas},
	author = {Kluyver, Thomas and Ragan-Kelley, Benjamin and Pérez, Fernando and Granger, Brian and Bussonier, Matthias and Frederic, Jonathan and Kelley, Kyle and Hamrick, Jessica and Grout, Jason and Corlay, Sylvan and Ivanov, Paul and Avila, Damián and Abdallan, Safia and Willing, Carol and Jupyter Development Team},
	year = {2016},
	pages = {87--90}
}

@article{perignon_certify_2019,
	title = {Certify reproducibility with confidential data},
	volume = {365},
	copyright = {Copyright © 2019, American Association for the Advancement of Science. http://www.sciencemag.org/about/science-licenses-journal-article-reuseThis is an article distributed under the terms of the Science Journals Default License.},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aaw2825},
	abstract = {A trusted third party certifies that results reproduce
A trusted third party certifies that results reproduce},
	language = {en},
	number = {6449},
	journal = {Science},
	author = {Pérignon, Christophe and Gadouche, Kamel and Hurlin, Christophe and Silberman, Roxane and Debonnel, Eric},
	year = {2019},
	pmid = {31296759},
	pages = {127--128}
}

@article{tennant_ten_2019,
	title = {Ten {Hot} {Topics} around {Scholarly} {Publishing}},
	volume = {7},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	doi = {10.3390/publications7020034},
	abstract = {The changing world of scholarly communication and the emerging new wave of \&lsquo;Open Science\&rsquo; or \&lsquo;Open Research\&rsquo; has brought to light a number of controversial and hotly debated topics. Evidence-based rational debate is regularly drowned out by misinformed or exaggerated rhetoric, which does not benefit the evolving system of scholarly communication. This article aims to provide a baseline evidence framework for ten of the most contested topics, in order to help frame and move forward discussions, practices, and policies. We address issues around preprints and scooping, the practice of copyright transfer, the function of peer review, predatory publishers, and the legitimacy of \&lsquo;global\&rsquo; databases. These arguments and data will be a powerful tool against misinformation across wider academic research, policy and practice, and will inform changes within the rapidly evolving scholarly publishing system.},
	language = {en},
	number = {2},
	journal = {Publications},
	author = {Tennant, Jonathan P. and Crane, Harry and Crick, Tom and Davila, Jacinto and Enkhbayar, Asura and Havemann, Johanna and Kramer, Bianca and Martin, Ryan and Masuzzo, Paola and Nobes, Andy and Rice, Curt and Rivera-López, Bárbara and Ross-Hellauer, Tony and Sattler, Susanne and Thacker, Paul D. and Vanholsbeeck, Marc},
	year = {2019},
	keywords = {copyright, impact factor, open access, open science, peer review, research evaluation, scholarly communication, Scopus, web of science},
	pages = {34}
}

@article{marwick_packaging_2018,
	title = {Packaging {Data} {Analytical} {Work} {Reproducibly} {Using} {R} (and {Friends})},
	volume = {72},
	issn = {0003-1305},
	doi = {10.1080/00031305.2017.1375986},
	abstract = {Computers are a central tool in the research process, enabling complex and large-scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognizable way for organizing the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
	number = {1},
	journal = {The American Statistician},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	year = {2018},
	keywords = {Computational science, Data science, Open source software, Reproducible research},
	pages = {80--88}
}

@article{pebesma_r_2012,
	title = {The {R} software environment in reproducible geoscientific research},
	volume = {93},
	issn = {2324-9250},
	doi = {10.1029/2012EO160003},
	abstract = {Reproducibility is an important aspect of scientific research, because the credibility of science is at stake when research is not reproducible. Like science, the development of good, reliable scientific software is a social process. A mature and growing community relies on the R software environment for carrying out geoscientific research. Here we describe why people use R and how it helps in communicating and reproducing research.},
	language = {en},
	number = {16},
	journal = {Eos, Transactions American Geophysical Union},
	author = {Pebesma, Edzer and N\"ust, Daniel and Bivand, Roger},
	year = {2012},
	keywords = {R project, reproducible research, 0520 Data analysis: algorithms and implementation, 1978 Software re-use, 0530 Data presentation and visualization, 1694 Instruments and techniques, 1819 Hydrology: Geographic Information Systems (GIS)},
	pages = {163--163}
}

@article{stodden_empirical_2018,
	title = {An empirical analysis of journal policy effectiveness for computational reproducibility},
	volume = {115},
	copyright = {© 2018 . Published under the PNAS license.},
	issn = {0027-8424, 1091-6490},
	doi = {10.1073/pnas.1708290115},
	abstract = {A key component of scientific communication is sufficient information for other researchers in the field to reproduce published findings. For computational and data-enabled research, this has often been interpreted to mean making available the raw data from which results were generated, the computer code that generated the findings, and any additional information needed such as workflows and input parameters. Many journals are revising author guidelines to include data and code availability. This work evaluates the effectiveness of journal policy that requires the data and code necessary for reproducibility be made available postpublication by the authors upon request. We assess the effectiveness of such a policy by (i) requesting data and code from authors and (ii) attempting replication of the published findings. We chose a random sample of 204 scientific papers published in the journal Science after the implementation of their policy in February 2011. We found that we were able to obtain artifacts from 44\% of our sample and were able to reproduce the findings for 26\%. We find this policy—author remission of data and code postpublication upon request—an improvement over no policy, but currently insufficient for reproducibility.},
	language = {en},
	number = {11},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Stodden, Victoria and Seiler, Jennifer and Ma, Zhaokun},
	year = {2018},
	pmid = {29531050},
	keywords = {reproducible research, data access, open science, code access, reproducibility policy},
	pages = {2584--2589}
}

@article{stodden_legal_2009,
	title = {The {Legal} {Framework} for {Reproducible} {Scientific} {Research}: {Licensing} and {Copyright}},
	volume = {11},
	issn = {1521-9615},
	shorttitle = {The {Legal} {Framework} for {Reproducible} {Scientific} {Research}},
	doi = {10.1109/MCSE.2009.19},
	number = {1},
	journal = {Computing in Science \& Engineering},
	author = {Stodden, Victoria},
	year = {2009},
	pages = {35--40}
}

@article{greenbaum_structuring_2017,
	title = {Structuring supplemental materials in support of reproducibility},
	volume = {18},
	issn = {1474-760X},
	doi = {10.1186/s13059-017-1205-3},
	abstract = {Supplements are increasingly important to the scientific record, particularly in genomics. However, they are often underutilized. Optimally, supplements should make results findable, accessible, interoperable, and reusable (i.e., “FAIR”). Moreover, properly off-loading to them the data and detail in a paper could make the main text more readable. We propose a hierarchical organization for supplements, with some parts paralleling and “shadowing” the main text and other elements branching off from it, and we suggest a specific formatting to make this structure explicit. Furthermore, sections of the supplement could be presented in multiple scientific “dialects”, including machine-readable and lay-friendly formats.},
	number = {1},
	journal = {Genome Biology},
	author = {Greenbaum, Dov and Rozowsky, Joel and Stodden, Victoria and Gerstein, Mark},
	year = {2017},
	pages = {64}
}

@inproceedings{katz_software_2018,
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Software {Citation} in {Theory} and {Practice}},
	isbn = {978-3-319-96418-8},
	doi = {10.1007/978-3-319-96418-8_34},
	abstract = {In most fields, computational models and data analysis have become a significant part of how research is performed, in addition to the more traditional theory and experiment. Mathematics is no exception to this trend. While the system of publication and credit for theory and experiment (journals and books, often monographs) has developed and has become an expected part of the culture, how research is shared and how candidates for hiring, promotion are evaluated, software (and data) do not have the same history. A group working as part of the FORCE11 community developed a set of principles for software citation that fit software into the journal citation system, allow software to be published and then cited, and there are now over 50,000 DOIs that have been issued for software. However, some challenges remain, including: promoting the idea of software citation to developers and users; collaborating with publishers to ensure that systems collect and retain required metadata; ensuring that the rest of the scholarly infrastructure, particularly indexing sites, include software; working with communities so that software efforts “count”; and understanding how best to cite software that has not been published.},
	language = {en},
	booktitle = {Mathematical {Software} – {ICMS} 2018},
	publisher = {Springer International Publishing},
	author = {Katz, Daniel S. and Chue Hong, Neil P.},
	editor = {Davenport, James H. and Kauers, Manuel and Labahn, George and Urban, Josef},
	year = {2018},
	keywords = {Bibliometrics, Credit, Software citation, Software identifiers, Software metadata, Software repositories},
	pages = {289--296}
}

@article{neumann_datacite_2014,
	title = {{DataCite} and {DOI} names for research data},
	volume = {28},
	issn = {1573-4951},
	doi = {10.1007/s10822-014-9776-5},
	abstract = {The publication of research data is still not a widespread practice in many disciplines. The lack of acceptance of data as scientific output equal to scientific articles, and the lack of suitable infrastructures for the storage of data make it difficult to publish and cite data independently. The global consortium DataCite was established in 2009 to overcome the challenges of data citation. The aim of the consortium is to establish easy access to data, to increase the acceptance of data publication and to support data archiving. The use of Digital Object Identifiers (DOI) provides an easy method to access and re-use research data. The DOI facilitates the citation of data and therefore increases the availability and acknowledgement of research data.},
	language = {en},
	number = {10},
	journal = {Journal of Computer-Aided Molecular Design},
	author = {Neumann, Janna and Brase, Jan},
	year = {2014},
	keywords = {Data citation, Digital Object Identifier, Global consortium, Research data},
	pages = {1035--1041}
}

@article{wilkinson_fair_2016,
	title = {The {FAIR} {Guiding} {Principles} for scientific data management and stewardship},
	volume = {3},
	copyright = {2016 Nature Publishing Group},
	issn = {2052-4463},
	doi = {10.1038/sdata.2016.18},
	abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders—representing academia, industry, funding agencies, and scholarly publishers—have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
	language = {en},
	journal = {Scientific Data},
	author = {Wilkinson, Mark D. and Dumontier, Michel and Aalbersberg, IJsbrand Jan and Appleton, Gabrielle and Axton, Myles and Baak, Arie and Blomberg, Niklas and Boiten, Jan-Willem and da Silva Santos, Luiz Bonino and Bourne, Philip E. and Bouwman, Jildau and Brookes, Anthony J. and Clark, Tim and Crosas, Mercè and Dillo, Ingrid and Dumon, Olivier and Edmunds, Scott and Evelo, Chris T. and Finkers, Richard and Gonzalez-Beltran, Alejandra and Gray, Alasdair J. G. and Groth, Paul and Goble, Carole and Grethe, Jeffrey S. and Heringa, Jaap and ’t Hoen, Peter A. C. and Hooft, Rob and Kuhn, Tobias and Kok, Ruben and Kok, Joost and Lusher, Scott J. and Martone, Maryann E. and Mons, Albert and Packer, Abel L. and Persson, Bengt and Rocca-Serra, Philippe and Roos, Marco and van Schaik, Rene and Sansone, Susanna-Assunta and Schultes, Erik and Sengstag, Thierry and Slater, Ted and Strawn, George and Swertz, Morris A. and Thompson, Mark and van der Lei, Johan and van Mulligen, Erik and Velterop, Jan and Waagmeester, Andra and Wittenburg, Peter and Wolstencroft, Katherine and Zhao, Jun and Mons, Barend},
	year = {2016},
	pages = {160018}
}

@book{xie_dynamic_2015,
	title = {Dynamic {Documents} with {R} and knitr, {Second} {Edition}},
	isbn = {978-1-4987-1697-0},
	abstract = {Quickly and Easily Write Dynamic Documents Suitable for both beginners and advanced users, Dynamic Documents with R and knitr, Second Edition makes writing statistical reports easier by integrating computing directly with reporting. Reports range from homework, projects, exams, books, blogs, and web pages to virtually any documents related to statistical graphics, computing, and data analysis. The book covers basic applications for beginners while guiding power users in understanding the extensibility of the knitr package. New to the Second Edition  A new chapter that introduces R Markdown v2 Changes that reflect improvements in the knitr package New sections on generating tables, defining custom printing methods for objects in code chunks, the C/Fortran engines, the Stan engine, running engines in a persistent session, and starting a local server to serve dynamic documents Boost Your Productivity in Statistical Report Writing and Make Your Scientific Computing with R Reproducible Like its highly praised predecessor, this edition shows you how to improve your efficiency in writing reports. The book takes you from program output to publication-quality reports, helping you fine-tune every aspect of your report.},
	language = {en},
	publisher = {CRC Press},
	author = {Xie, Yihui},
	year = {2015},
	keywords = {Business \& Economics / Statistics, Computers / Mathematical \& Statistical Software, Mathematics / Probability \& Statistics / General}
}

@article{lees_open_2012,
	title = {Open and {Free}: {Software} and {Scientific} {Reproducibility}},
	volume = {83},
	copyright = {© 2012 by the Seismological Society of America},
	issn = {0895-0695, 1938-2057},
	shorttitle = {Open and {Free}},
	doi = {10.1785/0220120091},
	abstract = {Recent scandals, retractions and proliferation of scientific research has reached a stage where scrutiny of scientific debate is now routinely reported in the public press as evidence of bungling, or, worse, dishonesty, in our profession (see Zimmer, 2012; Reay, 2010). High profile cases, like the discredited cancer research at Duke University or the notorious “Climate‐gate”, can be traced back to poor implementation of checks and balances on standard scientific practice. One remedy is to require researchers to use open methods of analysis, to share software, and to submit only reproducible analysis where it is feasible. Barriers to reproducibility are propriety (closed) software and computer platforms that encourage, rather than prevent, sloppy documentation. It is time to remind ourselves of efforts, perhaps started in the 1980’s, to reestablish standards of reproducibility (see Schwab et al. , 1996).

It has been a couple years now that I have acted as editor‐in‐chief of SRL, Seismological Research Letters . In the capacity of editor I handle papers submitted by authors all over the world. Some time ago a paper came across my desk formatted with an older version of a very popular word processor. I will not mention any names, but this software is used, nearly universally, by scientists and professionals around the world. The paper included equations formatted with an outdated system, a set of routines supplied by the corporate software publisher of the word processor that have since been superseded by newer, costly upgrades.

Since the submission was formatted in this manner, I could not …},
	language = {en},
	number = {5},
	journal = {Seismological Research Letters},
	author = {Lees, Jonathan M.},
	year = {2012},
	pages = {751--752}
}

@article{buck_solving_2015,
	title = {Solving reproducibility},
	volume = {348},
	copyright = {Copyright © 2015, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aac8041},
	language = {en},
	number = {6242},
	
	journal = {Science},
	author = {Buck, Stuart},
	year = {2015},
	pmid = {26113692},
	pages = {1403--1403}
}

@article{jupyter_binder_2018,
	title = {Binder 2.0 - {Reproducible}, interactive, sharable environments for science at scale},
	doi = {10.25080/Majora-4af1f417-011},
	journal = {Proceedings of the 17th Python in Science Conference},
	author = {Jupyter, Project and Bussonnier, Matthias and Forde, Jessica and Freeman, Jeremy and Granger, Brian and Head, Tim and Holdgraf, Chris and Kelley, Kyle and Nalvarte, Gladys and Osheroff, Andrew and Pacer, M. and Panda, Yuvi and Perez, Fernando and Ragan-Kelley, Benjamin and Willing, Carol},
	year = {2018},
	pages = {113--120}
}

@manual{nust_agile_2019,
	title = {{AGILE} {Reproducible} {Paper} {Guidelines}},
	doi = {10.17605/OSF.IO/CB7Z8},
	abstract = {Full and short paper submissions to the AGILE conference must include a Data and Software Availability sub-section as part of the Methods section. This document explains how to write that section and provides material for authors to increase computational reproducibility of their scholarly manuscripts. 
    Hosted on the Open Science Framework},
	language = {en},
	author = {N\"ust, Daniel and Ostermann, Frank and Sileryte, Rusne and Hofer, Barbara and Granell, Carlos and Teperek, Marta and Graser, Anita and Broman, Karl and Hettne, Kristina},
	year = {2019},
	organization = {OSF}
}

@misc{reproducible_agile,
  doi = {10.17605/OSF.IO/PHMCE},
  url = {https://reproducible-agile.github.io/},
  author = {N\"ust, Daniel and Ostermann, Frank and Sileryte, Rusne and Hofer, Barbara and Granell, Carlos and Teperek, Marta and Graser, Anita and Broman, Karl and Hettne, Kristina, and Konkol, Markus},
  title = {{Reproducible Publications at AGILE Conferences}},
  publisher = {Open Science Framework},
  year = {2019}
}

@article{stodden_best_2014,
	title = {Best {Practices} for {Computational} {Science}: {Software} {Infrastructure} and {Environments} for {Reproducible} and {Extensible} {Research}},
	volume = {2},
	copyright = {Authors who publish with this journal agree to the following terms:    Authors retain copyright and grant the journal right of first publication with the work simultaneously licensed under a  Creative Commons Attribution License  that allows others to share the work with an acknowledgement of the work's authorship and initial publication in this journal.  Authors are able to enter into separate, additional contractual arrangements for the non-exclusive distribution of the journal's published version of the work (e.g., post it to an institutional repository or publish it in a book), with an acknowledgement of its initial publication in this journal.  Authors are permitted and encouraged to post their work online (e.g., in institutional repositories or on their website) prior to and during the submission process, as it can lead to productive exchanges, as well as earlier and greater citation of published work (See  The Effect of Open Access ).  All third-party images reproduced on this journal are shared under Educational Fair Use. For more information on  Educational Fair Use , please see  this useful checklist prepared by Columbia University Libraries .   All copyright  of third-party content posted here for research purposes belongs to its original owners.  Unless otherwise stated all references to characters and comic art presented on this journal are ©, ® or ™ of their respective owners. No challenge to any owner’s rights is intended or should be inferred.},
	issn = {2049-9647},
	shorttitle = {Best {Practices} for {Computational} {Science}},
	doi = {10.5334/jors.ay},
	abstract = {The goal of this article is to coalesce a discussion around best practices for scholarly research that utilizes computational methods, by providing a formalized set of best practice recommendations to guide computational scientists and other stakeholders wishing to disseminate reproducible research, facilitate innovation by enabling data and code re-use, and enable broader communication of the output of computational scientific research. Scholarly dissemination and communication standards are changing to reflect the increasingly computational nature of scholarly research, primarily to include the sharing of the data and code associated with published results. We also present these Best Practices as a living, evolving, and changing document at http://wiki.stodden.net/Best\_Practices.},
	language = {en},
	number = {1},
	journal = {Journal of Open Research Software},
	author = {Stodden, Victoria and Miguez, Sheila},
	year = {2014},
	keywords = {archiving, best practices, code sharing, computational science, data sharing, open science, reproducible research, scientific method, wiki},
	pages = {e21}
}

@article{brinckman_computing_2018,
	title = {Computing environments for reproducibility: {Capturing} the “{Whole} {Tale}”},
	issn = {0167-739X},
	shorttitle = {Computing environments for reproducibility},
	doi = {10.1016/j.future.2017.12.029},
	abstract = {The act of sharing scientific knowledge is rapidly evolving away from traditional articles and presentations to the delivery of executable objects that integrate the data and computational details (e.g., scripts and workflows) upon which the findings rely. This envisioned coupling of data and process is essential to advancing science but faces technical and institutional barriers. The Whole Tale project aims to address these barriers by connecting computational, data-intensive research efforts with the larger research process—transforming the knowledge discovery and dissemination process into one where data products are united with research articles to create “living publications” or tales. The Whole Tale focuses on the full spectrum of science, empowering users in the long tail of science, and power users with demands for access to big data and compute resources. We report here on the design, architecture, and implementation of the Whole Tale environment.},
	journal = {Future Generation Computer Systems},
	author = {Brinckman, Adam and Chard, Kyle and Gaffney, Niall and Hategan, Mihael and Jones, Matthew B. and Kowalik, Kacper and Kulasekaran, Sivakumar and Ludäscher, Bertram and Mecum, Bryce D. and Nabrzyski, Jarek and Stodden, Victoria and Taylor, Ian J. and Turk, Matthew J. and Turner, Kandace},
	year = {2018},
	keywords = {Code sharing, Data sharing, Living publications, Provenance, Reproducibility}
}

@article{marwick_computational_2017,
	title = {Computational {Reproducibility} in {Archaeological} {Research}: {Basic} {Principles} and a {Case} {Study} of {Their} {Implementation}},
	volume = {24},
	issn = {1573-7764},
	shorttitle = {Computational {Reproducibility} in {Archaeological} {Research}},
	doi = {10.1007/s10816-015-9272-9},
	abstract = {The use of computers and complex software is pervasive in archaeology, yet their role in the analytical pipeline is rarely exposed for other researchers to inspect or reuse. This limits the progress of archaeology because researchers cannot easily reproduce each other’s work to verify or extend it. Four general principles of reproducible research that have emerged in other fields are presented. An archaeological case study is described that shows how each principle can be implemented using freely available software. The costs and benefits of implementing reproducible research are assessed. The primary benefit, of sharing data in particular, is increased impact via an increased number of citations. The primary cost is the additional time required to enhance reproducibility, although the exact amount is difficult to quantify.},
	language = {en},
	number = {2},
	journal = {Journal of Archaeological Method and Theory},
	author = {Marwick, Ben},
	year = {2017},
	keywords = {Software engineering, Open science, Computer programming, Reproducible research, Australian archaeology},
	pages = {424--450}
}

@book{r_core_team_r:_2019,
	address = {Vienna, Austria},
	title = {R: {A} {Language} and {Environment} for {Statistical} {Computing}},
	url = {https://www.R-project.org/},
	publisher = {R Foundation for Statistical Computing},
	author = {{R Core Team}},
	year = {2019}
}

@article{nosek_promoting_2015,
	title = {Promoting an open research culture},
	volume = {348},
	copyright = {Copyright © 2015, American Association for the Advancement of Science},
	issn = {0036-8075, 1095-9203},
	doi = {10.1126/science.aab2374},
	abstract = {Author guidelines for journals could help to promote transparency, openness, and reproducibility},
	language = {en},
	number = {6242},
	journal = {Science},
	author = {Nosek, B. A. and Alter, G. and Banks, G. C. and Borsboom, D. and Bowman, S. D. and Breckler, S. J. and Buck, S. and Chambers, C. D. and Chin, G. and Christensen, G. and Contestabile, M. and Dafoe, A. and Eich, E. and Freese, J. and Glennerster, R. and Goroff, D. and Green, D. P. and Hesse, B. and Humphreys, M. and Ishiyama, J. and Karlan, D. and Kraut, A. and Lupia, A. and Mabry, P. and Madon, T. and Malhotra, N. and Mayo-Wilson, E. and McNutt, M. and Miguel, E. and Paluck, E. Levy and Simonsohn, U. and Soderberg, C. and Spellman, B. A. and Turitto, J. and VandenBos, G. and Vazire, S. and Wagenmakers, E. J. and Wilson, R. and Yarkoni, T.},
	month = jun,
	year = {2015},
	pmid = {26113702},
	pages = {1422--1425}
}

@article{perkel_make_2019,
	title = {Make code accessible with these cloud services},
	volume = {575},
	copyright = {2019 Nature},
	doi = {10.1038/d41586-019-03366-x},
	abstract = {Container platforms let researchers run each other’s software — and check the results.},
	language = {en},
	journal = {Nature},
	author = {Perkel, Jeffrey M.},
	month = nov,
	year = {2019},
	pages = {247--248}
}

@misc{the_turing_way_community_turing_2019,
	title = {The {Turing} {Way}: {A} {Handbook} for {Reproducible} {Data} {Science}},
	shorttitle = {The {Turing} {Way}},
	url = {https://zenodo.org/record/3233986},
	abstract = {Reproducible research is necessary to ensure that scientific work can be trusted. Funders and publishers are beginning to require that publications include access to the underlying data and the analysis code. The goal is to ensure that all results can be independently verified and built upon in future work. This is sometimes easier said than done. Sharing these research outputs means understanding data management, library sciences, software development, and continuous integration techniques: skills that are not widely taught or expected of academic researchers and data scientists. The Turing Way is a handbook to support students, their supervisors, funders and journal editors in ensuring that reproducible data science is "too easy not to do". It will include training material on version control, analysis testing, and open and transparent communication with future users, and build on Turing Institute case studies and workshops. This project is openly developed and any and all questions, comments and recommendations are welcome at our github repository: https://github.com/alan-turing-institute/the-turing-way. Release log v0.0.4: Continuous integration chapter merged to master. v0.0.3: Reproducible environments chapter merged to master. v0.0.2: Version control chapter merged to master. v0.0.1: Reproducibility chapter merged to master.},
	publisher = {Zenodo},
	author = {{The Turing Way Community} and Becky Arnold and Louise Bowler and Sarah Gibson and Patricia Herterich and Rosie Higman and Anna Krystalli and Alexander Morley and Martin O'Reilly and Kirstie Whitaker},
	month = mar,
	year = {2019},
	doi = {10.5281/zenodo.3233986},
	annote = {This work was supported by The UKRI Strategic Priorities Fund under the EPSRC Grant EP/T001569/1, particularly the "Tools, Practices and Systems" theme within that grant, and by The Alan Turing Institute under the EPSRC grant EP/N510129/1.}
}

@article{foster_research_2018,
	title = {Research {Infrastructure} for the {Safe} {Analysis} of {Sensitive} {Data}},
	volume = {675},
	issn = {0002-7162},
	doi = {10.1177/0002716217742610},
	abstract = {To use administrative and other new data sources for the scientific study of human beings and human behavior, analysts need to be able both to connect to these new data and to deploy new methods for linking and analyzing the data. These efforts are often hindered by legal, technical, and operational difficulties. In this article, I examine how new digital research infrastructures can be used to reduce such barriers. Experiences with data stewardship in other scientific domains shows that appropriate infrastructure can enable the efficient, secure, and collaborative integration of domain expertise, data, and analysis capabilities. I review the state of the art in these areas and argue for the use of cloud-hosted enclaves as a safe interaction point for analysts, data, and software, and as a means of automating and thus professionalizing data stewardship processes.},
	language = {en},
	number = {1},
	journal = {The ANNALS of the American Academy of Political and Social Science},
	author = {Foster, Ian},
	month = jan,
	year = {2018},
	pages = {102--120}
}

@article{munafo_manifesto_2017,
	title = {A manifesto for reproducible science},
	volume = {1},
	copyright = {2017 Macmillan Publishers Limited},
	issn = {2397-3374},
	url = {https://www.nature.com/articles/s41562-016-0021},
	doi = {10.1038/s41562-016-0021},
	abstract = {Leading voices in the reproducibility landscape call for the adoption of measures to optimize key elements of the scientific process.},
	language = {en},
	number = {1},
	journal = {Nature Human Behaviour},
	author = {Munafò, Marcus R. and Nosek, Brian A. and Bishop, Dorothy V. M. and Button, Katherine S. and Chambers, Christopher D. and Sert, Nathalie Percie du and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J. and Ioannidis, John P. A.},
	month = jan,
	year = {2017},
	pages = {1--9}
}

@article{ram_git_2013,
	title = {Git can facilitate greater reproducibility and increased transparency in science},
	volume = {8},
	issn = {1751-0473},
	doi = {10.1186/1751-0473-8-7},
	abstract = {Reproducibility is the hallmark of good science. Maintaining a high degree of transparency in scientific reporting is essential not just for gaining trust and credibility within the scientific community but also for facilitating the development of new ideas. Sharing data and computer code associated with publications is becoming increasingly common, motivated partly in response to data deposition requirements from journals and mandates from funders. Despite this increase in transparency, it is still difficult to reproduce or build upon the findings of most scientific publications without access to a more complete workflow.},
	number = {1},
	journal = {Source Code for Biology and Medicine},
	author = {Ram, Karthik},
	month = feb,
	year = {2013},
	pages = {7}
}

@article{hrynaszkiewicz_publishers_2019,
	title = {Publishers’ {Responsibilities} in {Promoting} {Data} {Quality} and {Reproducibility}},
	url = {https://link.springer.com/chapter/10.1007/164_2019_290},
	doi = {10.1007/164_2019_290},
	abstract = {Scholarly publishers can help to increase data quality and reproducible research by promoting transparency and openness. Increasing transparency can be achieved by publishers in six key areas: (1)...},
	language = {en},
	author = {Hrynaszkiewicz, Iain},
	year = {2019},
	pages = {1--30}
}

@incollection{buckheit_wavelab_1995,
	series = {Lecture {Notes} in {Statistics}},
	title = {{WaveLab} and {Reproducible} {Research}},
	copyright = {©1995 Springer-Verlag New York},
	isbn = {978-0-387-94564-4 978-1-4612-2544-7},
	abstract = {Wavelab is a library of wavelet-packet analysis, cosine-packet analysis and matching pursuit. The library is available free of charge over the Internet. Versions are provided for Macintosh, UNIX and Windows machines. Wavelab makes available, in one package, all the code to reproduce all the figures in our published wavelet articles. The interested reader can inspect the source code to see exactly what algorithms were used, how parameters were set in producing our figures, and can then modify the source to produce variations on our results. WAVELAB has been developed, in part, because of exhortations by Jon Claerbout of Stanford that computational scientists should engage in “really reproducible” research.},
	language = {en},
	number = {103},
	booktitle = {Wavelets and {Statistics}},
	publisher = {Springer New York},
	author = {Buckheit, Jonathan B. and Donoho, David L.},
	editor = {Antoniadis, Anestis and Oppenheim, Georges},
	year = {1995},
	doi = {10.1007/978-1-4612-2544-7_5},
	keywords = {Probability Theory and Stochastic Processes},
	pages = {55--81}
}

@Manual{zen4r,
  title = {zen4R: Interface to 'Zenodo' REST API},
  author = {Emmanuel Blondel},
  year = {2020},
  note = {R package version 0.4-2},
  url = {https://CRAN.R-project.org/package=zen4R},
}

@dataset{codecheck_register,
  author       = {Daniel Nüst and
                  Stephen Eglen and
                  Iain Davies},
  title        = {{codecheckers/register: CODECHECK Register Deposit September 2020}},
  month        = sep,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {2020-09},
  doi          = {10.5281/zenodo.4059768},
  url          = {https://codecheck.org.uk/register/}
}

@misc{stark_before_2018,
	type = {News},
	title = {Before reproducibility must come preproducibility},
	copyright = {2018 Nature},
	abstract = {Instead of arguing about whether results hold up, let’s push to provide enough information for others to repeat the experiments, says Philip Stark.},
	language = {EN},
	urldate = {2018-05-25},
	journal = {Nature},
	author = {Stark, Philip B.},
	month = may,
	year = {2018},
	doi = {10.1038/d41586-018-05256-0}
}

@article{tennant_limitations_2020,
	title = {The limitations to our understanding of peer review},
	volume = {5},
	issn = {2058-8615},
	doi = {10.1186/s41073-020-00092-1},
	abstract = {Peer review is embedded in the core of our knowledge generation systems, perceived as a method for establishing quality or scholarly legitimacy for research, while also often distributing academic prestige and standing on individuals. Despite its critical importance, it curiously remains poorly understood in a number of dimensions. In order to address this, we have analysed peer review to assess where the major gaps in our theoretical and empirical understanding of it lie. We identify core themes including editorial responsibility, the subjectivity and bias of reviewers, the function and quality of peer review, and the social and epistemic implications of peer review. The high-priority gaps are focused around increased accountability and justification in decision-making processes for editors and developing a deeper, empirical understanding of the social impact of peer review. Addressing this at the bare minimum will require the design of a consensus for a minimal set of standards for what constitutes peer review, and the development of a shared data infrastructure to support this. Such a field requires sustained funding and commitment from publishers and research funders, who both have a commitment to uphold the integrity of the published scholarly record. We use this to present a guide for the future of peer review, and the development of a new research discipline based on the study of peer review.},
	number = {1},
	urldate = {2020-10-01},
	journal = {Research Integrity and Peer Review},
	author = {Tennant, Jonathan P. and Ross-Hellauer, Tony},
	month = apr,
	year = {2020},
	pages = {6}
}

% https://twitter.com/hertzpodcast/status/1334155945652449280
@audio{everythinghertz97,
  author={Quintana, Daniel and Heathers, James},
  title={97: Slow science},
  howpublished={Open Science Framework},
  organization={Everything Hertz},
  month=12,
  year=2019,
  series={Everything Hertz},
  doi = {10.17605/OSF.IO/XEU42},
  url = {https://osf.io/xeu42/},
  note={Sports analogy mentioned by Dan Quintana at the 55:15 minute mark.}
}

@article{konkol_publishing_2020,
	title = {Publishing computational research - a review of infrastructures for reproducible and transparent scholarly communication},
	volume = {5},
	issn = {2058-8615},
	url = {https://doi.org/10.1186/s41073-020-00095-y},
	doi = {10.1186/s41073-020-00095-y},
	abstract = {The trend toward open science increases the pressure on authors to provide access to the source code and data they used to compute the results reported in their scientific papers. Since sharing materials reproducibly is challenging, several projects have developed solutions to support the release of executable analyses alongside articles.},
	number = {1},
	urldate = {2020-07-14},
	journal = {Research Integrity and Peer Review},
	author = {Konkol, Markus and Nüst, Daniel and Goulier, Laura},
	month = jul,
	year = {2020},
	pages = {10}
}

@article{nust_improving_2020,
	title = {Improving reproducibility of geospatial conference papers – lessons learned from a first implementation of reproducibility reviews},
	copyright = {Copyright (c) 2020 Daniel Nüst, Frank Ostermann, Carlos Granell, Alexander Kmoch},
	issn = {2387-3086},
	url = {https://septentrio.uit.no/index.php/SCS/article/view/5601},
	doi = {10.7557/5.5601},
	abstract = {In an attempt to increase the reproducibility of contributions to a long-running and established geospatial conference series, the 23rd AGILE Conference on Geographic Information Science 2020 (https://agile-online.org/conference-2020) for the first time provided guidelines on preparing reproducible papers (Nüst et al., 2020) and appointed a reproducibility committee to evaluate computational workflows of accepted papers ( https://www.agile-giscience-series.net/review\_process.html). Here, the committee’s members report on the lessons learned from reviewing 23 accepted full papers and outline future plans for the conference series. In summary, six submissions were partially reproduced by reproducibility reviewers, whose reports are published openly on OSF ( https://osf.io/6k5fh/). These papers are promoted with badges on the proceedings’ website (https://agile-giss.copernicus.org/articles/1/index.html).
Compared to previous years’ submissions (cf. Nüst et al. 2018), the guidelines and increased community awareness markedly improved reproducibility. However, the reproduction attempts also revealed problems, most importantly insufficient documentation. This was partly mitigated by the non-blind reproducibility review, conducted after paper acceptance, where interaction between reviewers and authors can provide the input and attention needed to increase reproducibility. However, the reviews also showed that anonymisation and public repositories, when properly documented, can enable a successful reproduction without interaction, as was the case with one manuscript. Individual and organisational challenges due to the COVID-19 pandemic and the conference’s eventual cancellation increased the teething problems. Nevertheless, also under normal circumstances, future iterations will have to reduce the reviewer’s efforts to be sustainable, ideally by more readily executable workflows and a larger reproducibility committee.
Furthermore, we discuss changes to the reproducibility review process and their challenges. Reproducibility reports could be made available to “regular” reviewers, or the reports could be considered equally for acceptance/rejection decisions. Insufficient information or invalid arguments for not disclosing material could then lead to a submission being rejected or not being sent out to peer review. Further organisational improvements are a publication of reviewers’ activities in public databases, making the guidelines mandatory, and collecting data on used tools/repositories, spent efforts, and communications.
Finally, we summarise the revision of the guidelines, including their new section for reproducibility reviewers, and the status of the initiative “Reproducible Publications at AGILE Conferences” (https://reproducible-agile.github.io/initiative/), which we connect to related undertakings such as CODECHECK (Eglen et al., 2019). The AGILE Conference’s experiences may help other communities to transition towards more open and reproducible research publications.},
	language = {en},
	number = {4},
	urldate = {2020-12-03},
	journal = {Septentrio Conference Series},
	author = {Nüst, Daniel and Ostermann, Frank and Granell, Carlos and Kmoch, Alexander},
	month = sep,
	year = {2020},
	note = {Number: 4},
	keywords = {open science, peer review, reproducibility, reproducible research}
}

@article{petrovecki_role_2009,
	title = {The role of statistical reviewer in biomedical scientific journal},
	volume = {19},
	url = {https://www.biochemia-medica.com/en/journal/19/10.11613/BM.2009.020},
	doi = {10.11613/BM.2009.020},
	language = {en},
	number = {3},
	urldate = {2020-12-03},
	journal = {Biochemia Medica},
	author = {Petrovečki, Mladen},
	month = oct,
	year = {2009},
	note = {Publisher: Croatian Society of Medical Biochemistry and Laboratory Medicine},
	pages = {223--230},
	file = {Full Text PDF:/home/daniel/Zotero/storage/F33SLFJZ/Petrovečki - 2009 - The role of statistical reviewer in biomedical sci.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/ZHH2FYKU/fullArticle.html:text/html}
}

@article{petrovecki_role_2009,
	title = {The role of statistical reviewer in biomedical scientific journal},
	volume = {19},
	url = {https://www.biochemia-medica.com/en/journal/19/10.11613/BM.2009.020},
	doi = {10.11613/BM.2009.020},
	language = {en},
	number = {3},
	urldate = {2020-12-03},
	journal = {Biochemia Medica},
	author = {Petrovečki, Mladen},
	month = oct,
	year = {2009},
	note = {Publisher: Croatian Society of Medical Biochemistry and Laboratory Medicine},
	pages = {223--230}
}
